#!/bin/sh



########################################################################

# WHERE ARE ALL THE kSNP SCRIPTS?  
# IF YOU INSTALLED kSNP ANYWHERE OTHER THAN /user/local THEN YOU MUST MODIFY
# THIS TO POINT TO THE DIRECTORY WHERE YOU HAVE INSTALLED kSNP SCRIPTS

# Try to set this automatically from argv[0] (command path) - JN
# Per the tcsh man page, :h can be appended to show only the "head"
# (directory) from the "trailing" (filename) component.  $0 references
# the command issued when invoking the script.  The requirement that
# remains is that the other binaries continue to be co-located with
# this script, or be somewhere else in the PATH

# LEGACY TCSH
# set kSNP="$0:h"  # /usr/local/kSNP3/kSNP3 -> /usr/local/kSNP3
KSNPPATH=`dirname "${0}"`


########################################################################


#############
#############
#
# kSNP rewrite in Bash / Bourne shell starts here.
#
# We will slowly replace parts of this script's functionality with the same
# functionality in a replacement script written in Bash / Bourne.  As we
# implement a feature in Bash, we will remove the corresponding lines in this
# script, until this script is empty except for a call to the kSNP_bash script.
# At that point, we will remove this script and rename the bash script. 
#
#############
#############

#############
# Set up paths to required scripts.  Permits us to change them in only one place.
#############

ADD_PATHS="${KSNPPATH}/add_paths3"
LE2UNIX="${KSNPPATH}/LE2Unix"
CHECKFILENAMES="${KSNPPATH}/CheckFileNames"
MERGE_FASTA_READ="${KSNPPATH}/merge_fasta_reads3"
JELLYFISH="${KSNPPATH}/jellyfish"
GETQUANTILE="${KSNPPATH}/get_quantile3"
SUBSETMERS="${KSNPPATH}/subset_mers3"
DELETEALLELECONFLICTS="${KSNPPATH}/delete_allele_conflicts3"
PARALLELCOMMANDS="${KSNPPATH}/parallel_commands3"

# Other variables / files / directories.
NAMEERRORSFILE="NameErrors.txt"
THISDIR=`pwd`
SPLITNAME="fsplit"
FILE2GENOME="fileName2genomeName"
HASHSIZE=1000000000   # One billion.


#############
# Parse arguments
#############


# Technically our minimum # of arguments is 6... we can bail to error by testing
# this?

# Set default / initial values of each variable:
CMDLINE_ERROR=0    # No error initially
### Mandatory arguments
K=""
FASTA_LIST=""
DIR=""

### Optional arguments default value
MIN_FRACTION_WITH_LOCUS=""
ANNOTATE_LIST=""
SNPS_ALL=""
GENBANKFILE=""
NUM_CPUS=0         # 0 means determine ourselves.  Not accepted as user input
ALL_ANNOTATIONS=0
CORE=0
ML=0
NJ=0
VCF=0
DEBUG=0            # Permit user specifying whether debugging enabled on cmdline.


while [ ${#} -gt 0 ]  # While we have more arguments to process...
do
    case "${1}" in    # "switch" / case  based on what the argument is.
	-k)
	    K="${2}"
	    if [ 3 -gt "${K}" ] # Is K at least 3?
	    then
		CMDLINE_ERROR=1
		echo "Error: k must be at least 3"
	    fi
	    shift 2 # Argument and value
	    ;;
	
	-in)
	    FASTA_LIST=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${FASTA_LIST}" ] # Does FASTA_LIST file exist?
	    then
		echo "fasta_list: ${FASTA_LIST}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -in argument must be a file that exists (did not find ${FASTA_LIST})"
	    fi		
	    shift 2 # Argument and value
	    ;;

	-outdir)
	    DIR=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    echo "Output directory: ${DIR}"
	    # Where is this directory created?  Do we create with -p?
	    shift 2 # Argument and value
	    ;;
	
	-min_frac)
	    MIN_FRACTION_WITH_LOCUS="${2}"
	    # TODO: Add validation?
	    shift 2 # Argument and value
	    ;;

	-annotate)
	    ANNOTATE_LIST=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${ANNOTATE_LIST}" ] # Does ANNOTATE_LIST file exist?
	    then
		echo "annotate_list: ${ANNOTATE_LIST}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -annotate argument must be a file that exists (did not find ${ANNOTATE_LIST})"
	    fi		
	    shift 2 # Argument and value
	    ;;

	-SNPs_all)
	    SNPS_ALL=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${SNPS_ALL}" ] # Does SNPS_ALL file exist?
	    then
		echo "SNPs_all: ${SNPS_ALL}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -SNPs_all argument must be a file that exists (did not find ${SNPS_ALL})"
	    fi		
	    shift 2 # Argument and value
	    ;;
	
	-genbank)
	    GENBANKFILE=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${GENBANKFILE}" ] # Does GENBANKFILE file exist?
	    then
		echo "genbankFile: ${GENBANKFILE}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -genbank argument must be a file that exists (did not find ${GENBANKFILE})"
	    fi		
	    shift 2 # Argument and value
	    ;;
	
	-CPU)
	    NUM_CPUS="${2}"
	    if [ 1 -gt "${NUM_CPUS}" ] # Did the user specify a silly number?
	    then
		CMDLINE_ERROR=1
		echo "Error: -CPU must be at least 1"
	    fi
	    shift 2 # Argument and value
	    ;;
	
	-all_annotations)
	    ALL_ANNOTATIONS=1
	    shift # Argument
	    ;;
	
	-core)
	    CORE=1
	    shift # Argument
	    ;;

	-ML)
	    ML=1
	    shift # Argument
	    ;;

	-NJ)
	    NJ=1
	    shift # Argument
	    ;;

	-vcf)
	    VCF=1
	    shift # Argument
	    ;;

	-debug)
	    DEBUG=1
	    shift # Argument
	    ;;

	*)  # All other values are errors.          
	    CMDLINE_ERROR=1
	    echo "Error: Unrecognized argument (no valid argument: ${1})"
	    shift
	    ;;
    esac

done # Processing arguments

if [ -z "${K}" -o -z "${DIR}" -o -z "${FASTA_LIST}" ]
then
    CMDLINE_ERROR=1
    echo "Error: Must specify -k, -outdir, and -in.  At least one is missing."
fi


if [ 0 -lt "${CMDLINE_ERROR}" ]
then
    cat <<USAGE
Usage: kSNP3 -k <kmer length> -outdir <output directory> -in <input fasta file> [<optional arguments>...]

Required arguments:
 -k <kmer_length>
 -outdir <output_directory>
 -in <input_fastaFile_list>	

The input_fastaFile_list is a file listing the full path location of each genome
and the genome name, one line per genome, tab delimited between full path to
genome fasta file in column 1 and genome name in column 2. This format allows
multi-read,multi-chromosome, and multi-contig genomes, each genome in separate
fasta. If multiple chromosomes are listed as separate fasta entries in a single
genome file, positions and annotations are found for each gi number

Optional arguments:
 -min_frac <minimum_fraction_genomes_with_locus>  Create a parsimony tree based
 	   		 only on SNP loci that occur in at least this fraction of
			 genomes, for example -min_frac 0.5

 -annotate <annotate_list>  File listing genome names for which to find positions
 	   		 and annotate SNPs, names match column 2 of the -in file.

 -SNPs_all <path to SNPs all file>   If given then it uses existing SNPs instead
 	   	    	 of searching for new ones, and adds new genomes to the
			 existing analysis. Assumes only the new genomes are 
			 listed in the -in file.

 -all_annotations  	 Annotate each locus exhaustively with all annotations 
 			 in any of the annotated genomes. Without this option it
			 only provides the first annotation it comes to for a
			 given locus, checking in the order genomes are listed in
			 the -annotate file.

 -core	                 Calculate core SNPs and core SNP parsimony tree
 -ML	                 Calculate Maximum Likelihood tree
 -genbank <genbank.gbk>	 Source file for SNP annotation
 -CPU <num_CPU>		 Number of CPU's to use, (default to all)
 -NJ  			 Calculate a neighbor joining tree
 -vcf			 Create a vcf file using the first genome specified in 
 			 the -positions file as the reference genome

USAGE

    exit 1
fi # if there was a parsing error.

if [ 1 -eq "${DEBUG}" ]
then
    echo "Settings for this run:"
    echo "K=${K}"
    echo "FASTA_LIST=${FASTA_LIST}"
    echo "DIR=${DIR}"
    echo "MIN_FRACTION_WITH_LOCUS=${MIN_FRACTION_WITH_LOCUS}"
    echo "ANNOTATE_LIST=${ANNOTATE_LIST}"
    echo "SNPS_ALL=${SNPS_ALL}"
    echo "GENBANKFILE=${GENBANKFILE}"
    echo "NUM_CPUS=${NUM_CPUS}"
    echo "ALL_ANNOTATIONS=${ALL_ANNOTATIONS}"
    echo "CORE=${CORE}"
    echo "ML=${ML}"
    echo "NJ=${NJ}"
    echo "VCF=${VCF}"
    echo "DEBUG=${DEBUG}"
fi


#############
# END Parse arguments
#############



#############
# START Setup of environment, update user re: details.
#############


# Ensure our working directory is the directory specified in the commandline 
# arguments, even if it doesn't exist yet (TODO - Ensure directory created in 
# argument parsing above? Will be clearer that the dir will be created) - JN 
if [ ! -d "${DIR}" ]  # If the output directory doesn't exist...
then
    mkdir -p "${DIR}" || { echo "Unable to create output / working directory: ${DIR}" ; exit 1 ; }
fi
cd "${DIR}"

# This validation should be to STDERR, and shouldn't use state?  Or maybe the errors are
# complicated enough that we need to keep the details around for the user to use to address
# the errors?  TODO FIXME XXX
"${CHECKFILENAMES}" "${FASTA_LIST}"
if [ -e "${NAMEERRORSFILE}" ]
then
	echo "ERROR: kSNP terminated because error file ${NAMEERRORSFILE} is present."
	echo " Please review the contents of this file, correct any errors found, remove the file, and re-run kSNP"
	exit 1
fi

echo "Starting kSNP"
date
STARTSECONDS=`date +%s`

echo "Configuration for this run:"
echo "input fasta_list: ${FASTA_LIST}"
echo "output / working directory: ${DIR}"
echo "k=${K}"
echo "annotate_list file: ${ANNOTATE_LIST}"
if [ 1 -eq "${ALL_ANNOTATIONS}" ]   # Defaults to 0
then 
	echo "Report all annotations"
else
	echo "Report minimal annotations"
fi

if [ -n "${MIN_FRACTION_WITH_LOCUS}" ]  # Defaults to empty string.
then
	echo "min_fraction_with_locus: ${MIN_FRACTION_WITH_LOCUS}"
fi

if [ -n "${GENBANKFILE}" ]   # Already checked for existence when parsing arguments.
then
	echo "Genbank file for annotations (and any from NCBI with gi number which are automatically downloaded): ${GENBANKFILE}"
fi

if [ 0 -eq "${NUM_CPUS}" ]
then
	echo "Automatically determining number of CPUs to use:"
	OS=`uname`
       	echo "The operating system is ${OS}"

	if [ "Darwin" = "${OS}" ] # MacOS
	then
		NUM_CPUS=`/usr/sbin/system_profiler SPHardwareDataType | awk '/Total Number of Cores/ {print $5}'`
	else # Linux
		NUM_CPUS=`cat /proc/cpuinfo | grep processor | wc -l`
	fi

	echo "Discovered ${NUM_CPUS}"

	if [ 1 -gt "${NUM_CPUS}" ]
	then
	       	NUM_CPUS=8
		echo "Could not automatically determine number of CPUs available, defaulting to ${NUM_CPUS}"
        fi
fi

echo "Number CPUs: ${NUM_CPUS}"


echo "SNPS_ALL=${SNPS_ALL}"
echo "GENBANKFILE=${GENBANKFILE}"
echo "CORE=${CORE}"
echo "ML=${ML}"
echo "NJ=${NJ}"
echo "VCF=${VCF}"
echo "DEBUG=${DEBUG}"


### Preprocess FASTA input file.

#chesk the fasta genome files to be sure line endings are Unix and fix if they are not
# Copy the original input file ${FASTA_LIST} to a specified name in the output directory for easier reference
cp -f "${FASTA_LIST}" fasta_list

# Process each file listed in the input file to correct the line endings if needed and if possible
"${LE2UNIX}" fasta_list

# Then process the fasta_list file to correct its line-endings.
perl -i -pe 's/\015\012/\012/g' fasta_list    # Windows to unix
perl -i -pe 's/\015/\012/g' fasta_list	      # Mac old format to unix



### Preprocess Annotation input file.

# WARNING:
# The file 'annotate_list' in the working / output directory is maintained state.
# This means different behavior if the output directory is re-used.
# WARNING

# Benefits to operating on a copy? (does this program modify 'annotate_list'
# file?) - JN
if [ -e "${ANNOTATE_LIST}" ]
then
	cp -f "${ANNOTATE_LIST}" annotate_list
else
	touch annotate_list
fi

# Which means that the conversion to unix line-endings needs to be redone...? - JN
#DOS to unix
perl -i -pe 's/\015\012/\012/g' annotate_list	# Windows to unix
perl -i -pe 's/\015/\012/g' annotate_list	# Mac old format to unix

# Output contents of annotate_list to the console (why?) - JN
echo "Finished genomes for finding SNP positions:"
cat annotate_list
echo ""


# Make lookup table of genome names and fsplit# files, and create fsplit# files by merging entries of multi-contig/multi-read input genomes. 
COUNT=0
# Note that this is sensitive to extra lines, including blank lines?
NUM_SEQS=`wc -l fasta_list | awk '{print $1}' `

echo "Number of input sequences: ${NUM_SEQS}"

# Ensure fileName2genomeName file exists and is empty.
rm "${FILE2GENOME}" 2> /dev/null # Ignore errors
touch "${FILE2GENOME}"

# VAR


# Output fasta_list input file, with lines numbered from zero in the first column, and write
# a mapping from fsplit<line number> to genome name (tab separated) into fileName2genomeName
# file
COUNT=0
cat fasta_list | while read FILE GENOME   # Read the contents of each line into two variables.
do
    # Output to the screen the association between the count, the genome name and the file.
    echo "${COUNT}\t${GENOME}\t${FILE}"
    
    FSPLIT="${SPLITNAME}${COUNT}"
    # Combine multiple FASTA file records in a file into a single record by joining them with 'N'
    # NOTE: This can take measurable amount of time for FASTA files with lots of records.  Cache this data? - JN FXIME TODO XXX
    "${MERGE_FASTA_READ}" "${FILE}" > "${FSPLIT}"
    
    # Mapping of fsplit filename to genome
    echo "${FSPLIT}\t${GENOME}" >> "${FILE2GENOME}"
    
    # Increment count variable
    COUNT=`expr "${COUNT}" + 1`
done


#############
# FINISHED Setup of environment, update user re: details.
#############




#############
#############
#
# Run jellyfish on the merged input files to produce kmers list files.
#
#############
#############

# Input: List of merged input files (in the $FILE2GENOME file here) and the files themselves
# Output: A kmers_all version of each input file.


KMERSALLPREFIX="kmers_all"
UNSORTEDKMERSPREFIX="unsortedkmers"

date # Output the date for timing info.
echo "Running jellyfish to find k-mers"

# Extract the names of the files from the list we already created, and iterate through the list.
cat "${FILE2GENOME}" | while read FILE REST
do
    KMERSALL="${KMERSALLPREFIX}.${FILE}"
    UNSORTEDKMERS="${UNSORTEDKMERSPREFIX}.${FILE}"
    if [ ! -s "${KMERSALL}" ]
    then
	JELLYFILE="Jelly.${FILE}"
	echo "${FILE}"  # Perhaps we should print the genome instead?  It is in $REST at this time

	# Extract all of the k-mers from the input fasta files ( along with counts? or is that just a placeholder? )
	"${JELLYFISH}" count -C -o "${JELLYFILE}" -m "${K}" -s "${HASHSIZE}" -t "${NUM_CPUS}" "${FILE}"

	# Output is not sorted.
	"${JELLYFISH}" dump -c "${JELLYFILE}" > "${UNSORTEDKMERS}"

	# Not clear that output needs to be sorted yet.
	sort "${UNSORTEDKMERS}" > "${KMERSALL}"
	
	# Note that we aren't removing the $JELLYFILE?  It is smaller than the origin file, to be fair.
	rm "${UNSORTEDKMERS}"
    fi
done

echo "Finished running jellyfish."


#############
# START Filtering k-mers from jellyfish based on frequency.
#############


### FIXME TODO XXX Removed portion of the kSNP3 tcsh script referencing 'sa' tool as unused.  It overlaps with jellyfish function above.

FREQUENCYPREFIX="freq"
KMERSPREFIX="kmers"

echo "Filtering out low-frequency kmers."

# Extract the names of the files from the list of input files we already created, and iterate through the list.
cat "${FILE2GENOME}" | while read FILE REST
do
    FREQUENCY="${FREQUENCYPREFIX}.${FILE}"
    KMERSALL="${KMERSALLPREFIX}.${FILE}"
    KMERS="${KMERSPREFIX}.${FILE}"

    awk '{print $2}' "${KMERSALL}" > "${FREQUENCY}"

    MIN_KMER_COVERAGE=`"${GETQUANTILE}" "${FREQUENCY}"`
    echo "minimum kmer coverage for ${FILE} is ${MIN_KMER_COVERAGE}"

    # Filter out k-mers with frequency lower than the $MIN_KMER_COVERAGE
    awk -v "m=${MIN_KMER_COVERAGE}" '$2>=m {print}' "${KMERSALL}" > "${KMERS}"

    # Remove temporary frequency file
    rm "${FREQUENCY}"
done

date
echo "Filtered out low-frequency kmers."

#############
# FINISHED Filtering k-mers from jellyfish based on frequency.
#############


#############
#############
#
# kSNP rewrite in Bash / Bourne shell stops here.
#
#############
#############


#############
#
# Remove conflicting k-mers.  A k-mer is conflicting there are multiple
# 'alleles' (k-mers matching in all but the center) within a given genome.
#
# This is an issue because you cannot discern a mutation between two genomes
# when there are multiple matching k-mers _within_ a genome using this tool
# which is restricted to looking at the k-mers without the full genome context.
#
#############

### Input: kmers.fsplit<N> (all)
### Output: Dir.fsplit<N>/X*.mers (many for each fsplit<N> source) 
### Output: kmers_fsplit<N>.conflictsDeleted (each)
### Transform: k-mers in the kmers.fsplit<N> file sorted into buckets of 
###   identical prefix
### Transform: A conflict is when a k-mer matches another in every character
###   except the center.  These are removed from the buckets of identical
###   prefix above, and the resulting k-mers are simply listed in the output
###   file (.conflictsDeleted) in sorted order.

# Challenges:
#  - Creates a lot of files that then need to be managed.
#  - Parallelizes without regard to size of dataset (confirm?)
#  - LOTS of sorting.


DIRPREFIX="Dir"
REMOVECONFLICTSCOMMANDS="cmds_remove_conflicting"

# Remove kmers from a genome if there are conflicting alleles in that genome 
echo "Removing conflicting kmers from each genome with conflicting alleles"

cat "${FILE2GENOME}" | while read FILE REST
do
    GENOMEDIRECTORY="${DIRPREFIX}.${FILE}"
    KMERS="../${KMERSPREFIX}.${FILE}"

    echo "${FILE}"
    mkdir "${GENOMEDIRECTORY}"
    cd "${GENOMEDIRECTORY}"

    "${SUBSETMERS}" "${KMERS}"

    rm "${REMOVECONFLICTSCOMMANDS}" 2> /dev/null
    touch "${REMOVECONFLICTSCOMMANDS}"

    # I think these are the output files from subset_mers3? TODO FIXME XXX
    # Note that this can use xargs v. easily.
    for SUBSET in *.mers     
    do
	echo "${DELETEALLELECONFLICTS} ${SUBSET}" >> "${REMOVECONFLICTSCOMMANDS}"
    done
    
    "${PARALLELCOMMANDS}" "${NUM_CPUS}" "${REMOVECONFLICTSCOMMANDS}"

    cd ..   # Return to the working directory.

done

echo "Finished removing conflicting kmers"
date


exit 0





### Input: kmers.fsplit<N> (all)
### Output: Dir.fsplit<N>/X*.mers (many for each fsplit<N> source) 
### Output: kmers_fsplit<N>.conflictsDeleted (each)
### Transform: k-mers in the kmers.fsplit<N> file sorted into buckets of 
###   identical prefix
### Transform: A conflict is when a k-mer matches another in every character
###   except the center.  These are removed from the buckets of identical
###   prefix above, and the resulting k-mers are simply listed in the output
###   file (.conflictsDeleted) in sorted order.

# VAR
set DirPrefix="Dir"
set SubsetMers="$kSNP/subset_mers3"
set RemoveConflicts_Commands="cmds_remove_conflicting" # Note that this is likely a temp file.
set DeleteAlleleConflicts="$kSNP/delete_allele_conflicts3"

# Candidate for rewriting in bash + parallel. - JN

# Remove kmers from a genome if there are conflicting alleles in that genome 
echo "Removing conflicting kmers from each genome with conflicting alleles"
date
foreach f (fsplit*)
	# VAR
	set GenomeDirectory="$DirPrefix.$f"
	set KMers="../$KMersPrefix.$f" # This should be a full instead of relative path?

	echo $f
	mkdir Dir.$f
	cd Dir.$f
	# Read from fsplit<N>, output into buckets (typically 5-mers) in the
	# kmers.fsplit<N> directory named with the prefix common to the entries.mers
	$kSNP/subset_mers3 ../kmers.$f
	printf "" >! cmds_remove_conflicting 
	foreach subset (*.mers)
		echo "$kSNP/delete_allele_conflicts3 $subset" >> cmds_remove_conflicting
	end
	$kSNP/parallel_commands3 $num_cpus cmds_remove_conflicting
	cd ..
end
echo "Finished removing conflicting kmers"
date


### Input: Dir.fsplit<n>/X*.mers
### Output: X*.mers
### Transform: Merge sort across fsplit<N> groups, with removal of duplicates.

# VAR
set SubsetMerList="$kSNP/subset_mer_list3"
set MerList="mer_list"
set Sort_Commands="cmds_sort" # Note this is likely a temp file.

echo "Merged sorted kmer files and remove duplicates"
date
$kSNP/subset_mer_list3 > ! mer_list
printf "" >! cmds_sort
foreach subset (`cat mer_list`)
	echo "sort  -m  -u Dir.*/$subset.conflictsDeleted  > $subset" >> cmds_sort
end
$kSNP/parallel_commands3 $num_cpus cmds_sort
echo "Finished merging kmers across genomes"
date

# VAR
set SubsetSNPsAll="$kSNP/subset_SNPs_all3"
set SNPsAllSuffix="SNPs_all"
set SNPsToFastaQuery="$kSNP/SNPs2fastaQuery3"
set SNPLociPrefix="SNP_loci"
set SNPLociSuffix="fasta"

################################ NEW
# Do not look for new SNPs, just find old ones from  -SNPs_all  input option
if (  $?SNPs_all  ) then 
	#  ADD GENOMES to existing SNP analysis
	printf "Using existing SNPs from $SNPs_all file\n"
	date
	$kSNP/subset_SNPs_all3 "$SNPs_all"
	foreach subset (`cat mer_list`)
		# VAR
		set SubsetSNPs="$subset.$SNPsAllSuffix"
		set SubsetLoci="$SNPLociPrefix.$subset.$SNPLociSuffix"

		if (-s $subset.SNPs_all) then
			$kSNP/SNPs2fastaQuery3 $subset.SNPs_all >! SNP_loci.$subset.fasta 
		endif
	end
endif
################################## if no -SNPs_all file or it is empty, then find new SNPs

### Input: X*.mers (required to be sorted)
### Output: SNP_loci.X*.mers.fasta (fasta format)
### Transform: Create sorted list of k-mers that have been seen and are SNPs
###   (multiple k-mers differing in only the central monomer) in fasta format,
###   with the generic (k-mer with central monomer wildcarded) indicated in the
###   description ( >... prefix to the fasta data)

if (! $?SNPs_all  ) then 
	# do all the SNP finding
	printf "Discovering new SNPs\n\n"
	date

	echo "Finding kmers with multiple allele variants"
	printf "" >! cmds_pick_snps
	foreach subset (`cat mer_list`)
		echo "$kSNP/pick_snps_from_kmer_genome_counts3 $subset > SNP_loci.$subset.fasta" >> cmds_pick_snps
	end
	$kSNP/parallel_commands3 $num_cpus cmds_pick_snps
	echo "Finished finding kmers with multiple allele variants"
endif
   
 # Find which genome has which allele variant, by comparing the SNP_loci and Dir.$f/$subset.conflictsDeleted  foreach genome
date
echo "Finding allele in each genome"
printf "" >! cmds_find_allele
foreach f (fsplit*)
	foreach subset (`cat mer_list`)
		echo "$kSNP/find_allele3 SNP_loci.$subset.fasta  Dir.$f/$subset.conflictsDeleted $f > Dir.$f/SNPs.$subset" >> cmds_find_allele
	end
end
$kSNP/parallel_commands3 $num_cpus cmds_find_allele
# Combine partitioned SNPs into one file (not sorted?) - JN
foreach f (fsplit*)
	cat Dir.$f/SNPs.*.mers >! Dir.$f/SNPs
end

# Run mummer to find the position of each SNP in the finished genomes. Don't do this for unassembled draft genomes or merged raw read genomes, since positional information is not informative.

# This isn't done for 'Run1', and I don't have mummer output to review, so 
# skipping for now.  Want to review to see if GNU parallel can improve. - JN
if (-s annotate_list) then
	echo "Finding SNP positions in finished genomes using mummer."
	date
	printf "" >! cmds_mummer
	printf "" >! cmds_parse_mummer
	foreach genome (`cat annotate_list`) 
		set test=`grep -w  $genome fileName2genomeName | wc -l`
		set f=`grep -w  $genome fileName2genomeName | awk '{print $1}'`
		if ($test > 0 ) then
			set file=`grep -w  $genome fasta_list  | awk -F'\011' '{print $1}'`
			printf "genome: $genome  in Dir.$f\n"
			awk -F'\011' '{print ">" $1 "_" $2 "\n" $3 }' Dir.$f/SNPs >! Dir.$f/SNPs.fasta
			printf "$kSNP/mummer -maxmatch -l $k -b -c  Dir.$f/SNPs.fasta "'"'"$file"'"'" > Dir.$f/mummer.out\n" >> cmds_mummer
			printf "$kSNP/parse_mummer4kSNP3  Dir.$f/mummer.out  > Dir.$f/SNP.positions\n" >> cmds_parse_mummer
		endif
	end
	$kSNP/parallel_commands3 $num_cpus cmds_mummer
	$kSNP/parallel_commands3 $num_cpus cmds_parse_mummer
	date
	echo "Finished finding SNP positions in finished genomes using mummer."
endif

# concatenate SNP files for each genome into one and sort it, and number the loci
echo "Concatenate results for each genome and sort by locus to create  SNPs_all_labelLoci"
date
printf "" >! all_SNPs_unsorted
foreach f (fsplit*)
	set test=`grep -w  $f fileName2genomeName | wc -l`
	# Note, this will filter out all fsplit files not referenced in 
	# fileName2genomeName.  Maybe simpler to simply go from the contents of this
	# file instead? - JN
	if ($test > 0 ) then
		set genome=`grep -w  $f fileName2genomeName | awk '{print $2}'`
		printf "genome: $genome  in Dir.$f\n"
		if (-s Dir.$f/SNP.positions) then
			# This is based on mummer output, above. - JN
			# Add field containing filename (fsplit<N>) inserted in the 4th column.
			awk -F'\011' -v f=$f '{print $1 "\t" $2 "\t" $3  "\t" f "\t" $4}' Dir.$f/SNP.positions  >> all_SNPs_unsorted
			#cat Dir.$f/SNP.positions >> all_SNPs_unsorted
		else
			# If no mummer output, data is pulled from SNPs file, with the 3rd 
			# column being 'x', the 4th column being genome name from the file
			# above, and the fifth column being blank (instead of from mummmer
			# data).
			awk -v genome=$genome '{print  $1 "\t" $2 "\tx\t" genome "\t" }' Dir.$f/SNPs >> all_SNPs_unsorted
		endif
	endif
end
if (  $?SNPs_all ) then 
	# Remove 1st column from SNPs_all file and append to unsorted SNPs list. - JN
	# use existing SNP numbering
	awk -F'\011'  '{print $2 "\t" $3 "\t" $4  "\t" $5 "\t" $6 "\t" $7}' "$SNPs_all" >> all_SNPs_unsorted
endif
# Maybe it makes sense to do a merge sort over just appending a bunch of things
# and then sorting?  Not clear how long this is.  Example 1 is under 1M entries
# and sorts in under 1 second on my computer. - JN
sort -u all_SNPs_unsorted >! all_SNPs_sorted
# Cannot find this command: number_SNPs_all3 - JN
# It exists in the binary distribution. - JN
# Additional observations about this executable:  Written in perl, compiled to
# binary using ActiveState's ActivePerl.  Takes a single commandline argument
# (will bail, possibly after creating a spurious output file if missing), and
# will create a file named <argument>_labelLoci as well as a COUNT_SNPs file.
# Output in testingwas the same as the content of the COUNT_SNPs file. - JN
# all_SNPs sorted to all_SNPs_sorted_labelLoci doesn't add any lines, does
# seem to maintain sorting by the first column in the original file (kmers?), but
# does NOT maintain sorting by subsequent columns.  Appears to:
# separate distinct kmers with newlines, and apply a single sequential number
# to each distinct kmer, prepending that number on each line that kmer appears.
$kSNP/number_SNPs_all3 all_SNPs_sorted
$kSNP/rename_from_table3 all_SNPs_sorted_labelLoci fileName2genomeName SNPs_all


# Set reference genome for vcf file to the be first finished genome, if this is empty, then set it to be the first genome in the input fasta file.
if (-s annotate_list) then
	set ref_genome=`head -1 annotate_list`
endif
if !($?ref_genome) then
	set ref_genome=`head -1 fileName2genomeName | awk '{print $2}'`
endif

# Did not review this path due to not executing in Run1.  TODO - JN
if ($?vcf ) then
	$kSNP/parse_SNPs2VCF3 SNPs_all VCF.$ref_genome.vcf  $ref_genome
endif

echo "Finished finding SNPs"
date


# Suggest prompting user to delete the temporary files directory if the run was
# successful?  Also suggest having a unique temporary directory for each run
# instead of deleting the previous temporary directory automatically. - JN


# You can delete this Directory if everything works, but it's useful for debugging in case the run fails
rm -r TemporaryFilesToDelete
mkdir TemporaryFilesToDelete
mv -f Dir.* TemporaryFilesToDelete/.
if (-e cmds_mummer) then 
	mv -f cmds_mummer TemporaryFilesToDelete/.
	mv -f cmds_parse_mummer TemporaryFilesToDelete/.
endif
mv -f  *.mers TemporaryFilesToDelete/.
mv -f Jelly.* TemporaryFilesToDelete/.
mv -f SNP_loci.*.mers.fasta TemporaryFilesToDelete/.
mv -f kmers*  TemporaryFilesToDelete/.
mv -f fsplit* TemporaryFilesToDelete/.
mv -f  all_SNPs_unsorted  TemporaryFilesToDelete/.
mv -f  all_SNPs_sorted* TemporaryFilesToDelete/.
mv -f mer_list TemporaryFilesToDelete/.
mv -f *.mers.SNPs_all TemporaryFilesToDelete/.


##probes_from_SNPs_all_kmers $probe_prefix_label

## Create a SNP matrix and fasta, for inputting to PHYLIP, FastTreeMP or other tools like SplitsTree
$kSNP/SNPs_all_2_fasta_matrix3 SNPs_all SNPs_all_matrix.fasta SNPs_all_matrix

printf "parsimony\n" >! tree_list1
printf "parsimony\n" >! tree_list2

############### Make tree using SNP matrix
echo "Building parsimony tree"

# Build parsimony tree
$kSNP/parsimonator -s SNPs_all_matrix -n SNPs_all -N 100 -p 1234

# get all the best scoring trees
# Note: Score == length. - JN
set best_parsimony_tree_score=`grep "Parsimony tree" RAxML_info.SNPs_all | sort -k6 -n | head -1 | awk '{print $6}'`
set best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_all | awk -v score=$best_parsimony_tree_score '$6==score {print $14}'`
set Num_best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_all | awk -v score=$best_parsimony_tree_score '$6==score {print $14}' | wc -l | awk '{print $1}'`
printf "Number of most parsimonious trees from SNPs_all: $Num_best_parsimony_trees\n"
printf "Score of those trees: $best_parsimony_tree_score\n"

cat $best_parsimony_trees >! intree

# Get majority consensus tree
rm outfile outtree
#PHYLIP consense was the only tool i found  that forced resolution of every branch. FastTree to give it branch lengths will crash if some notes have splits to >2 children. But you need to modify seq.h and phylip.h before compiling consense to allow longer names so they don't get truncated
echo "Y\n" | $kSNP/consense

# Give it branch lengths, optimized for the consensus parsimony tree.
# Input to force_binary_tree is one tree per file.
$kSNP/force_binary_tree outtree outtree.resolved
$kSNP/FastTreeMP -nt -pseudo   -nome -mllen -gamma -gtr -intree outtree.resolved SNPs_all_matrix.fasta >! tree.parsimony.tre
mv RAxML* TemporaryFilesToDelete/.


### This section does similar to above section, except for different input file
### SNPs_all has been replaced by SNPs_in_majorit<min_fraction_with_locus> ...
### The above should maybe be proceduralized to reduce code repetition?
###  - JN


###
###  BEGIN TEST ALPHA
###
###  This starts a long conditional ending in a loop far below, also marked
###  with label above (except END).
###


## Build parsimony tree from SNPs_in_majority"$min_fraction_with_locus"
if ($?min_fraction_with_locus) then 
	printf "Getting SNPs_in_majority$min_fraction_with_locus and building tree\n"
	$kSNP/core_SNPs3 SNPs_all fileName2genomeName $min_fraction_with_locus
	$kSNP/SNPs_all_2_fasta_matrix3 SNPs_in_majority"$min_fraction_with_locus"  SNPs_in_majority"$min_fraction_with_locus"_matrix.fasta SNPs_in_majority"$min_fraction_with_locus"_matrix

	# Build parsimony tree
	# Not sure what arguments are here.  -N appears to be # of trees to generate?
	# It is definitely associated with # of files to generate (0 - N-1)
	$kSNP/parsimonator -s SNPs_in_majority"$min_fraction_with_locus"_matrix -n SNPs_majority"$min_fraction_with_locus" -N 100 -p 1234

	# get all the best scoring trees
	# Find the best score...
	set best_parsimony_tree_score=`grep "Parsimony tree" RAxML_info.SNPs_majority"$min_fraction_with_locus" | sort -k6 -n | head -1 | awk '{print $6}'`
	# Grab the elements with the best score...
	set best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_majority"$min_fraction_with_locus" | awk -v score=$best_parsimony_tree_score '$6==score {print $14}'`
	# Finally, count how many elements we grabbed.
	set Num_best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_majority"$min_fraction_with_locus" | awk -v score=$best_parsimony_tree_score '$6==score {print $14}' | wc -l | awk '{print $1}'`

	# Output a summary to user.
	printf "Number of most parsimonious trees for SNPs_in_majority$min_fraction_with_locus : $Num_best_parsimony_trees\n"
	printf "Score of those trees: $best_parsimony_tree_score\n"


	cat $best_parsimony_trees >! intree

	# Get majority consensus tree
	rm outfile outtree
	#Find consensus parsimony tree
	echo "Y\n" | $kSNP/consense

	# Give it branch lengths, optimized for the consensus parsimony tree.
	# Script making use of biology related perl modules - JN
	$kSNP/force_binary_tree outtree outtree.resolved
	# Multiprocessing software. - JN
	$kSNP/FastTreeMP -nt -pseudo   -nome -mllen -gamma -gtr -intree outtree.resolved SNPs_in_majority"$min_fraction_with_locus"_matrix.fasta  >! tree.majority"$min_fraction_with_locus".tre
	mv RAxML* TemporaryFilesToDelete/.


	# The below takes away -nome -mllen -intree.  Look up what that changes, try to figure out why? - JN

	# Uncomment the following line to build ML majority tree, and write over the parsimony majority tree just built
	#$kSNP/FastTreeMP  -nt -pseudo  -gamma   -gtr SNPs_in_majority"$min_fraction_with_locus"_matrix.fasta  >!  tree.majority"$min_fraction_with_locus".tre


	# Can this loop execute more than once?  Why a foreach? - JN
	foreach t (  majority"$min_fraction_with_locus" )
		$kSNP/label_tree_nodes3 tree.$t.tre   > ! tree_nodeLabel.$t.tre
		$kSNP/tree_nodes3 tree_nodeLabel."$t".tre  nodes.$t
		if (-s tree_nodeLabel.$t.tre ) then
			echo "Placing SNPs on nodes $t tree"
			$kSNP/SNPs2nodes-new3 SNPs_in_majority"$min_fraction_with_locus"  nodes.$t.perlhash tree_nodeLabel.$t.tre  Node_SNP_counts.$t
			if (-e COUNT_Homoplastic_SNPs) then
				mv COUNT_Homoplastic_SNPs COUNT_Homoplastic_SNPs.$t
			endif
			if (-e ClusterInfo) then
				mv ClusterInfo ClusterInfo.$t
			endif
			if (-e Homoplasy_groups) then
				mv Homoplasy_groups Homoplasy_groups.$t
			endif
			date
			echo "Finished placing SNPs on nodes $t tree"
			printf "name_on_tree\tSNP_counts\n" >! tip_SNP_counts.$t
			grep "node: " Node_SNP_counts.$t | grep -w "NumberTargets: 1" | awk '{print $2 "\011" $6}' >> tip_SNP_counts.$t

			if (-s tree_nodeLabel.$t.tre.rerooted) then
				rm -f tree_nodeLabel.$t.tre
				mv -f tree_nodeLabel.$t.tre.rerooted tree_nodeLabel.$t.tre
			endif

			#rm_node_names_from_tree tree_nodeLabel.$t.tre tree.$t.tre # don't overwrite tree.$t.tre anymore since we want the support values in original file.

			$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.tre tree_AlleleCounts.$t.tre 0
			$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.NodeLabel.tre tree_AlleleCounts.$t.NodeLabel.tre 1

		endif
	end
endif

###
###  END TEST ALPHA
###


# Note that there seems to be at least some duplication from conditional above. - JN
# At some point take a thorough look to compare, and then factor out the
# differences to make it easier to understand.
#

###
###  START TEST BETA
###
###  This starts a long conditional ending in a loop far below, also marked
###  with label above (except END).
###

##Building parsimony tree from only the core SNPs
if ($?core) then 
	printf "Getting core SNPs"
	if (! $?min_fraction_with_locus) then
		$kSNP/core_SNPs3 SNPs_all fileName2genomeName 0.5
	endif
	$kSNP/SNPs_all_2_fasta_matrix3 core_SNPs core_SNPs_matrix.fasta core_SNPs_matrix

	# Build parsimony tree
	$kSNP/parsimonator -s core_SNPs_matrix  -n SNPs_core -N 100 -p 1234

	# get all the best scoring trees
	set best_parsimony_tree_score=`grep "Parsimony tree" RAxML_info.SNPs_core | sort -k6 -n | head -1 | awk '{print $6}'`
	set best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_core | awk -v score=$best_parsimony_tree_score '$6==score {print $14}'`

	set Num_best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_core | awk -v score=$best_parsimony_tree_score '$6==score {print $14}' | wc -l | awk '{print $1}'`

	printf "Number of most parsimonious trees for SNPs_core : $Num_best_parsimony_trees\n"
	printf "Score of those trees: $best_parsimony_tree_score\n"


	cat $best_parsimony_trees >! intree

	# Get majority consensus tree
	rm outfile outtree
	#Find consensus parsimony tree
	echo "Y\n" | $kSNP/consense

	# Give it branch lengths, optimized for the consensus parsimony tree.
	$kSNP/force_binary_tree outtree outtree.resolved
	$kSNP/FastTreeMP -nt -pseudo   -nome -mllen -gamma -gtr -intree outtree.resolved core_SNPs_matrix.fasta  >! tree.core.tre
	mv RAxML* TemporaryFilesToDelete/.

	# Uncomment the following line to build ML core tree, and write over the parsimony core tree just built
	#  $kSNP/FastTreeMP -nt  -gamma   -gtr core_SNPs_matrix.fasta  >!  tree.core.tre

	if (-s core_SNPs) then
		foreach t (  core )
			$kSNP/label_tree_nodes3 tree.$t.tre   > ! tree_nodeLabel.$t.tre
			$kSNP/tree_nodes3 tree_nodeLabel."$t".tre  nodes.$t
			if (-s tree_nodeLabel.$t.tre ) then
				echo "Placing SNPs on nodes $t tree"
				$kSNP/SNPs2nodes-new3 core_SNPs nodes.$t.perlhash tree_nodeLabel.$t.tre  Node_SNP_counts.$t
				if (-e COUNT_Homoplastic_SNPs) then
					mv COUNT_Homoplastic_SNPs COUNT_Homoplastic_SNPs.$t
				endif
				if (-e ClusterInfo) then
					mv ClusterInfo ClusterInfo.$t
				endif
				if (-e Homoplasy_groups) then
					mv Homoplasy_groups Homoplasy_groups.$t
				endif
				date
				echo "Finished placing SNPs on nodes $t tree"
				echo ""
				printf "name_on_tree\tSNP_counts\n" >! tip_SNP_counts.$t
				grep "node: " Node_SNP_counts.$t | grep -w "NumberTargets: 1" | awk '{print $2 "\011" $6}' >> tip_SNP_counts.$t

				if (-s tree_nodeLabel.$t.tre.rerooted) then
					rm -f tree_nodeLabel.$t.tre
					mv -f tree_nodeLabel.$t.tre.rerooted tree_nodeLabel.$t.tre
				endif

				#rm_node_names_from_tree tree_nodeLabel.$t.tre tree.$t.tre # don't overwrite tree.$t.tre anymore since we want the support values in original file.

				$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.tre tree_AlleleCounts.$t.tre 0
				$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.NodeLabel.tre tree_AlleleCounts.$t.NodeLabel.tre 1

			endif
		end
	endif
endif

## Building ML FastTree tree from all SNPs
if ($?ML) then
	$kSNP/FastTreeMP  -nt -pseudo  -gamma -gtr SNPs_all_matrix.fasta >!  tree.ML.tre
	printf "ML\n" >> tree_list1
	printf "ML\n" >> tree_list2
endif


if ( $?nj) then
	echo "Building NJ tree"
	date
	# NOTE:  This next line can take a long time if there are million+ SNP loci and 100+ genomes. SNP_matrix2dist_matrix does loops, so it's slow, should be parallelized.  Probably should try the PHYLIP program, although scores might be different since i count them as somewhat closer if they share a locus but not the allele than if they don't even share the locus. But since NJ SNP trees are not accurate anyway, i'm not inclined to spend anymore time since no one should use this option.
	# Above seems clear - JN
	$kSNP/SNP_matrix2dist_matrix3 SNPs_all_matrix >! NJ.dist.matrix
	$kSNP/distance_tree3 >! tree.NJ.tre
	echo "Finished building NJ tree"
	printf "NJ\n" >> tree_list1
	printf "NJ\n" >> tree_list2
	date
endif

#######################
 
$kSNP/find_unresolved_clusters3 tree.parsimony.tre >! unresolved_clusters

date
echo "Finding nodes"

foreach t ( `cat tree_list1` ) 
	if (-s tree."$t".tre) then
		# Opportunity to make this a subroutine?
		$kSNP/label_tree_nodes3 tree.$t.tre   > ! tree_nodeLabel.$t.tre
		$kSNP/tree_nodes3 tree_nodeLabel."$t".tre  nodes.$t
		echo "Placing SNPs on nodes $t tree"
		$kSNP/SNPs2nodes-new3 SNPs_all nodes.$t.perlhash tree_nodeLabel.$t.tre  Node_SNP_counts.$t
		if (-e COUNT_Homoplastic_SNPs) then
			mv COUNT_Homoplastic_SNPs COUNT_Homoplastic_SNPs.$t
		endif
		if (-e ClusterInfo) then
			mv ClusterInfo ClusterInfo.$t
		endif
		if (-e Homoplasy_groups) then
			mv Homoplasy_groups Homoplasy_groups.$t
		endif
		date
		echo "Finished placing SNPs on nodes $t tree"
		echo ""
	endif
end


# Relabel trees with SNP counts at nodes
foreach t (  `cat tree_list1` ) 
	if (-s tree."$t".tre) then

		printf "name_on_tree\tSNP_counts\n" >! tip_SNP_counts.$t
		grep "node: " Node_SNP_counts.$t | grep -w "NumberTargets: 1" | awk '{print $2 "\011" $6}' >> tip_SNP_counts.$t

		if (-s tree_nodeLabel.$t.tre.rerooted) then
			rm -f tree_nodeLabel.$t.tre
			mv -f tree_nodeLabel.$t.tre.rerooted tree_nodeLabel.$t.tre
		endif

		#rm_node_names_from_tree tree_nodeLabel.$t.tre tree.$t.tre # don't overwrite tree.$t.tre anymore since we want the support values in original file.

		$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.tre tree_AlleleCounts.$t.tre 0
		$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.NodeLabel.tre tree_AlleleCounts.$t.NodeLabel.tre 1
	endif
end

mv -f nodes.* TemporaryFilesToDelete/.
mv -f tree_tipAlleleCounts.*.NodeLabel.tre TemporaryFilesToDelete/.
mv -f tree_nodeLabel.* TemporaryFilesToDelete/.

########
# find proteins where SNPs land, codons, amino acids, and identify nonsynonymous SNPs
echo "Annotating SNPs."
date

# Only get genbank file and annoate if there is positional information for some genomes, ie. annotate_list is not empty
if (-s annotate_list) then 

	# Get whole genome annotations from genbank, unfortunately you have to get the whole genbank file with sequence data, since the much smaller feature table does not have mature peptides making viral annotation useless with polyproteins only.
	set count=0
	printf "" >! headers.annotate_list
	foreach genome (`cat annotate_list`) 
		set file_check=`grep -w  $genome fasta_list  | wc -l`
		if ($file_check > 0 ) then
			set file=`grep -w  $genome fasta_list  | awk -F'\011' '{print $1}'`
			printf "$file\n"
			$kSNP/get_genbank_file3 "$file" genbank_from_NCBI.gbk.$count
			fgrep ">" "$file" | sed -e "s/^>/>$genome /" >> headers.annotate_list
			@ count ++
		endif
	end
	cat genbank_from_NCBI.gbk.* | grep -v BioProject  >! genbank_from_NCBI.gbk
	rm genbank_from_NCBI.gbk.*


	# The annotate_SNPs_from_genbankFiles3 is a complicated script; deserves review / commenting. TODO - JN
	if (-e "$genbankFile" ) then 
		$kSNP/annotate_SNPs_from_genbankFiles3   -all $all_annotations  $genbankFile
	else
		$kSNP/annotate_SNPs_from_genbankFiles3   -all $all_annotations 
	endif

	printf "Num_NotAnnotatedRegion\tAnnotatedNotProtein\tNum_NonSynon\tNum_Synon\tNS/S\tNSfractionOfAnnotated\tNumLoci\tNum_InAnnotatedGenomes\tNum_NotInAnnotatedGenome\n" >! Annotation_summary
	set i=SNP_annotations
	set num_notInAnnotatedGenome=`grep  NotInAnnotatedGenome $i |  awk '  {print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set num_UnAnnRegion=`grep  UnannotatedRegion $i |  awk '  {print $1}' | sort -u | wc -l | awk '{print $1}'`  
	set num_AnnNotProtein=`grep  NotProteinCoding $i |  awk '  {print $1}' | sort -u | wc -l | awk '{print $1}'`  

	set NS_total=`grep -v LocusNum $i |  awk ' $3>0 {print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set Num_loci=`grep -v LocusNum $i |  awk '{print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set Num_loci_in_annotated=`grep -v LocusNum $i | grep -v  NotInAnnotatedGenome |  awk '{print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set S_total=`perl -e "print ($Num_loci_in_annotated-$NS_total)"`
	if ($S_total > 0) then
		set NS_Sratio=`perl -e "print $NS_total/$S_total"`
	else
		set NS_Sratio="inf"
	endif
	if ($Num_loci_in_annotated > 0) then 
		set NSfraction_overall=`perl -e "print $NS_total/$Num_loci_in_annotated"`
	else
		set NSfraction_overall="inf"
	endif

	printf "$num_UnAnnRegion\t$num_AnnNotProtein\t$NS_total\t$S_total\t$NS_Sratio\t$NSfraction_overall\t$Num_loci\t$Num_loci_in_annotated\t$num_notInAnnotatedGenome\n"  >> Annotation_summary


	$kSNP/parse_protein_annotation_counts3 SNP_annotations >!  Protein_Annotation_counts

	echo "Finished SNP annotation."
endif

# ParAnn is the compiled version of ParAnn.py, presumably.  Should be verified,
# and the process for compiling should be determined.  Once this is understood,
# perhaps a makefile for the binaries?  TODO - JN
#run ParAnn
$kSNP/ParAnn

echo "Finished running kSNP"
date
set endseconds=`date +%s`
set elapsedTime=`perl -e "print (($endseconds-$startseconds)/60/60)"`
echo "Elapsed time for kSNP in hours: $elapsedTime"


mv cmds* TemporaryFilesToDelete/.
mv tree_list1 TemporaryFilesToDelete/.
mv tree_list2 TemporaryFilesToDelete/.
mv -f fileName2genomeName TemporaryFilesToDelete/.
rm intree outtree outfile
rm SNP_annotations

if (-s SNPs_all && -s tree.parsimony.tre && -s tree_AlleleCounts.parsimony.tre && -s unresolved_clusters && -s COUNT_SNPs && $DEBUG<1) then
	rm -r TemporaryFilesToDelete
endif

exit

###
### Code after this section is preserved history, not live. - JN
###



##########################################################################################################
##########################################################################################################

# HRE finder is not updated to work with kSNP3.  Use kSNP2 if you want to use HREfinder.
#  In case you want to run HREFinder  at http://sourceforge.net/projects/hrefinder/ 
# set your path to the hreFinder code  "set hre=/path/to/hreFinder"
# and comment out the exit line above.
# YOU MUST HAVE ALL THE GENOMES IN THE -p annotate_list LIST. FOR HREFINDER YOU NEED POSITIONAL 
# INFORMATION FOR ALL OF THEM, EVEN THE DRAFT GENOMES THAT ARE ASSEMBLED INTO A FEW LARGE CONTIGS. 
# If some draft genomes are in alot of contigs, it is recommended that
# you remove those and rerun kSNP before attempting hreFinder. 
# Don't run hreFinder with genomes that are raw unassembled reads.


###### Run hreFinder to predict series of SNPs likely to have been involved in homologous recombination events

set hre=/usr/gapps/kpath/hreFinder   


if (-s SNPs_all) then

# Set reference genome for vcf file to the be first finished genome, if this is empty, then set it to be the first genome in the input fasta file.
if (-s annotate_list) then
    set ref_genome=`head -1 annotate_list`
endif
if !($?ref_genome) then
    set ref_genome=`head -1 fileName2genomeName | awk '{print $2}'`
endif


foreach tree (`cat tree_list2`)
mkdir  HRE.$tree
cd HRE.$tree
$hre/run_config.py ../tree.$tree.tre    ../fastainput ../SNPs_all $ref_genome

echo ""
echo $tree
echo "Number of SNPs involved in HRE events:"
awk '$1!="" {print $1}' hreSNPs | sort -u | wc -l
echo "Number of HRE events:"
grep -v HRE_events hre_from_to_c | awk ' total=total+$5 {} END {print total}'
echo "Number of HRE events from outside tree:"
grep -v HRE_events hre_from_to_c | grep outside | awk ' total=total+$5 {} END {print total}'


cd ..
end

endif

exit


# Set up standing db of genbank files so you don't have to go online to annotate SNPs
mkdir GenbankFiles
cd GenbankFiles
foreach domain ( Viruses Bacteria )
mkdir $domain
cd $domain
foreach type (gbk)
mkdir Temp
cd Temp
wget "ftp://ftp.ncbi.nih.gov/genomes/$domain/all.$type.tar.gz"
tar -xvzf all.$type.tar.gz
rm *.tar.gz
mv */*  ..
rm -r *
cd ..
rm -r Temp
end
cd ..
end

# get gbk files for plasmids
foreach domain ( Plasmids)
mkdir $domain
cd $domain
foreach type (gbk)
wget "ftp://ftp.ncbi.nih.gov/genomes/$domain/plasmids.all.$type.tar.gz"
tar -xvzf plasmids.all.$type.tar.gz
mv am/ftp-genomes/Plasmids/$type/* .
rm -r am
rm *.tar.gz
end
cd ..
end
