#!/bin/sh



########################################################################

# WHERE ARE ALL THE kSNP SCRIPTS?  
# IF YOU INSTALLED kSNP ANYWHERE OTHER THAN /user/local THEN YOU MUST MODIFY
# THIS TO POINT TO THE DIRECTORY WHERE YOU HAVE INSTALLED kSNP SCRIPTS

# Try to set this automatically from argv[0] (command path) - JN
# Per the tcsh man page, :h can be appended to show only the "head"
# (directory) from the "trailing" (filename) component.  $0 references
# the command issued when invoking the script.  The requirement that
# remains is that the other binaries continue to be co-located with
# this script, or be somewhere else in the PATH

# LEGACY TCSH
# set kSNP="$0:h"  # /usr/local/kSNP3/kSNP3 -> /usr/local/kSNP3
KSNPPATH=`dirname "${0}"`


########################################################################


#############
#############
#
# kSNP rewrite in Bash / Bourne shell starts here.
#
# We will slowly replace parts of this script's functionality with the same
# functionality in a replacement script written in Bash / Bourne.  As we
# implement a feature in Bash, we will remove the corresponding lines in this
# script, until this script is empty except for a call to the kSNP_bash script.
# At that point, we will remove this script and rename the bash script. 
#
#############
#############

#############
# Set up paths to required scripts.  Permits us to change them in only one place.
#############

ADD_PATHS="${KSNPPATH}/add_paths3"
LE2UNIX="${KSNPPATH}/LE2Unix"
CHECKFILENAMES="${KSNPPATH}/CheckFileNames"
MERGE_FASTA_READ="${KSNPPATH}/merge_fasta_reads3"
JELLYFISH="${KSNPPATH}/jellyfish"
GETQUANTILE="${KSNPPATH}/get_quantile3"
SUBSETMERS="${KSNPPATH}/subset_mers3"
DELETEALLELECONFLICTS="${KSNPPATH}/delete_allele_conflicts3"
PARALLELCOMMANDS="${KSNPPATH}/parallel_commands3"
SUBSETMERLIST="${KSNPPATH}/subset_mer_list3"
SUBSETSNPSALL="${KSNPPATH}/subset_SNPs_all3"
SNPSTOFASTAQUERY="${KSNPPATH}/SNPs2fastaQuery3"
PICKSNPSFROMKMERS="${KSNPPATH}/pick_snps_from_kmer_genome_counts3"
FINDALLELE="${KSNPPATH}/find_allele3"
MUMMER="${KSNPPATH}/mummer"
PARSEMUMMER="${KSNPPATH}/parse_mummer4kSNP3"
NUMBERSNPS="${KSNPPATH}/number_SNPs_all3"
RENAMEFROMTABLE="${KSNPPATH}/rename_from_table3"
PARSESNPSTOVCF="${KSNPPATH}/parse_SNPs2VCF3"
SNPSTOFASTAMATRIX="${KSNPPATH}/SNPs_all_2_fasta_matrix3.pl"  # NOTE: This is a .pl file and probably should be the name without a suffix. - JN
PARSIMONATOR="${KSNPPATH}/parsimonator"


# Other variables / files / directories.
NAMEERRORSFILE="NameErrors.txt"
THISDIR=`pwd`
SPLITNAME="fsplit"
FILE2GENOME="fileName2genomeName"
HASHSIZE=1000000000   # One billion.
FINDALLELECMDS="cmds_find_allele"
SNPSPREFIX="SNPs"
CONFLICTSSUFFIX="conflictsDeleted"
MERSSUFFIX="mers"

MUMMERCMDS='cmds_mummer'
PARSEMUMMERCMDS='cmds_parse_mummer'

MUMMEROUTPUT="mummer.out"
SNPPOSITIONS="SNP.positions"

KMERSALLPREFIX="kmers_all"
UNSORTEDKMERSPREFIX="unsortedkmers"
NUMTREES=100
PARSIMONYSEED=1234




#############
# Parse arguments
#############


# Technically our minimum # of arguments is 6... we can bail to error by testing
# this?

# Set default / initial values of each variable:
CMDLINE_ERROR=0    # No error initially
### Mandatory arguments
K=""
FASTA_LIST=""
DIR=""

### Optional arguments default value
MIN_FRACTION_WITH_LOCUS=""
ANNOTATE_LIST=""
SNPS_ALL=""
GENBANKFILE=""
NUM_CPUS=0         # 0 means determine ourselves.  Not accepted as user input
ALL_ANNOTATIONS=0
CORE=0
ML=0
NJ=0
VCF=0
DEBUG=0            # Permit user specifying whether debugging enabled on cmdline.


while [ ${#} -gt 0 ]  # While we have more arguments to process...
do
    case "${1}" in    # "switch" / case  based on what the argument is.
	-k)
	    K="${2}"
	    if [ 3 -gt "${K}" ] # Is K at least 3?
	    then
		CMDLINE_ERROR=1
		echo "Error: k must be at least 3"
	    fi
	    shift 2 # Argument and value
	    ;;
	
	-in)
	    FASTA_LIST=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${FASTA_LIST}" ] # Does FASTA_LIST file exist?
	    then
		echo "fasta_list: ${FASTA_LIST}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -in argument must be a file that exists (did not find ${FASTA_LIST})"
	    fi		
	    shift 2 # Argument and value
	    ;;

	-outdir)
	    DIR=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    echo "Output directory: ${DIR}"
	    # Where is this directory created?  Do we create with -p?
	    shift 2 # Argument and value
	    ;;
	
	-min_frac)
	    MIN_FRACTION_WITH_LOCUS="${2}"
	    # TODO: Add validation?
	    shift 2 # Argument and value
	    ;;

	-annotate)
	    ANNOTATE_LIST=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${ANNOTATE_LIST}" ] # Does ANNOTATE_LIST file exist?
	    then
		echo "annotate_list: ${ANNOTATE_LIST}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -annotate argument must be a file that exists (did not find ${ANNOTATE_LIST})"
	    fi		
	    shift 2 # Argument and value
	    ;;

	-SNPs_all)
	    SNPS_ALL=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${SNPS_ALL}" ] # Does SNPS_ALL file exist?
	    then
		echo "SNPs_all: ${SNPS_ALL}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -SNPs_all argument must be a file that exists (did not find ${SNPS_ALL})"
	    fi		
	    shift 2 # Argument and value
	    ;;
	
	-genbank)
	    GENBANKFILE=`"${ADD_PATHS}" "${2}" "${THISDIR}"`
	    if [ -e "${GENBANKFILE}" ] # Does GENBANKFILE file exist?
	    then
		echo "genbankFile: ${GENBANKFILE}"
	    else
		CMDLINE_ERROR=1
		echo "Error: -genbank argument must be a file that exists (did not find ${GENBANKFILE})"
	    fi		
	    shift 2 # Argument and value
	    ;;
	
	-CPU)
	    NUM_CPUS="${2}"
	    if [ 1 -gt "${NUM_CPUS}" ] # Did the user specify a silly number?
	    then
		CMDLINE_ERROR=1
		echo "Error: -CPU must be at least 1"
	    fi
	    shift 2 # Argument and value
	    ;;
	
	-all_annotations)
	    ALL_ANNOTATIONS=1
	    shift # Argument
	    ;;
	
	-core)
	    CORE=1
	    shift # Argument
	    ;;

	-ML)
	    ML=1
	    shift # Argument
	    ;;

	-NJ)
	    NJ=1
	    shift # Argument
	    ;;

	-vcf)
	    VCF=1
	    shift # Argument
	    ;;

	-debug)
	    DEBUG=1
	    shift # Argument
	    ;;

	*)  # All other values are errors.          
	    CMDLINE_ERROR=1
	    echo "Error: Unrecognized argument (no valid argument: ${1})"
	    shift
	    ;;
    esac

done # Processing arguments

if [ -z "${K}" -o -z "${DIR}" -o -z "${FASTA_LIST}" ]
then
    CMDLINE_ERROR=1
    echo "Error: Must specify -k, -outdir, and -in.  At least one is missing."
fi


if [ 0 -lt "${CMDLINE_ERROR}" ]
then
    cat <<USAGE
Usage: kSNP3 -k <kmer length> -outdir <output directory> -in <input fasta file> [<optional arguments>...]

Required arguments:
 -k <kmer_length>
 -outdir <output_directory>
 -in <input_fastaFile_list>	

The input_fastaFile_list is a file listing the full path location of each genome
and the genome name, one line per genome, tab delimited between full path to
genome fasta file in column 1 and genome name in column 2. This format allows
multi-read,multi-chromosome, and multi-contig genomes, each genome in separate
fasta. If multiple chromosomes are listed as separate fasta entries in a single
genome file, positions and annotations are found for each gi number

Optional arguments:
 -min_frac <minimum_fraction_genomes_with_locus>  Create a parsimony tree based
 	   		 only on SNP loci that occur in at least this fraction of
			 genomes, for example -min_frac 0.5

 -annotate <annotate_list>  File listing genome names for which to find positions
 	   		 and annotate SNPs, names match column 2 of the -in file.

 -SNPs_all <path to SNPs all file>   If given then it uses existing SNPs instead
 	   	    	 of searching for new ones, and adds new genomes to the
			 existing analysis. Assumes only the new genomes are 
			 listed in the -in file.

 -all_annotations  	 Annotate each locus exhaustively with all annotations 
 			 in any of the annotated genomes. Without this option it
			 only provides the first annotation it comes to for a
			 given locus, checking in the order genomes are listed in
			 the -annotate file.

 -core	                 Calculate core SNPs and core SNP parsimony tree
 -ML	                 Calculate Maximum Likelihood tree
 -genbank <genbank.gbk>	 Source file for SNP annotation
 -CPU <num_CPU>		 Number of CPU's to use, (default to all)
 -NJ  			 Calculate a neighbor joining tree
 -vcf			 Create a vcf file using the first genome specified in 
 			 the -positions file as the reference genome

USAGE

    exit 1
fi # if there was a parsing error.

if [ 1 -eq "${DEBUG}" ]
then
    echo "Settings for this run:"
    echo "K=${K}"
    echo "FASTA_LIST=${FASTA_LIST}"
    echo "DIR=${DIR}"
    echo "MIN_FRACTION_WITH_LOCUS=${MIN_FRACTION_WITH_LOCUS}"
    echo "ANNOTATE_LIST=${ANNOTATE_LIST}"
    echo "SNPS_ALL=${SNPS_ALL}"
    echo "GENBANKFILE=${GENBANKFILE}"
    echo "NUM_CPUS=${NUM_CPUS}"
    echo "ALL_ANNOTATIONS=${ALL_ANNOTATIONS}"
    echo "CORE=${CORE}"
    echo "ML=${ML}"
    echo "NJ=${NJ}"
    echo "VCF=${VCF}"
    echo "DEBUG=${DEBUG}"
fi


#############
# END Parse arguments
#############



#############
# START Setup of environment, update user re: details.
#############


# Ensure our working directory is the directory specified in the commandline 
# arguments, even if it doesn't exist yet (TODO - Ensure directory created in 
# argument parsing above? Will be clearer that the dir will be created) - JN 
if [ ! -d "${DIR}" ]  # If the output directory doesn't exist...
then
    mkdir -p "${DIR}" || { echo "Unable to create output / working directory: ${DIR}" ; exit 1 ; }
fi
cd "${DIR}"

# This validation should be to STDERR, and shouldn't use state?  Or maybe the errors are
# complicated enough that we need to keep the details around for the user to use to address
# the errors?  TODO FIXME XXX
"${CHECKFILENAMES}" "${FASTA_LIST}"
if [ -e "${NAMEERRORSFILE}" ]
then
	echo "ERROR: kSNP terminated because error file ${NAMEERRORSFILE} is present."
	echo " Please review the contents of this file, correct any errors found, remove the file, and re-run kSNP"
	exit 1
fi

echo "Starting kSNP"
date
STARTSECONDS=`date +%s`

echo "Configuration for this run:"
echo "input fasta_list: ${FASTA_LIST}"
echo "output / working directory: ${DIR}"
echo "k=${K}"
echo "annotate_list file: ${ANNOTATE_LIST}"
if [ 1 -eq "${ALL_ANNOTATIONS}" ]   # Defaults to 0
then 
	echo "Report all annotations"
else
	echo "Report minimal annotations"
fi

if [ -n "${MIN_FRACTION_WITH_LOCUS}" ]  # Defaults to empty string.
then
	echo "min_fraction_with_locus: ${MIN_FRACTION_WITH_LOCUS}"
fi

if [ -n "${GENBANKFILE}" ]   # Already checked for existence when parsing arguments.
then
	echo "Genbank file for annotations (and any from NCBI with gi number which are automatically downloaded): ${GENBANKFILE}"
fi

if [ 0 -eq "${NUM_CPUS}" ]
then
	echo "Automatically determining number of CPUs to use:"
	OS=`uname`
       	echo "The operating system is ${OS}"

	if [ "Darwin" = "${OS}" ] # MacOS
	then
		NUM_CPUS=`/usr/sbin/system_profiler SPHardwareDataType | awk '/Total Number of Cores/ {print $5}'`
	else # Linux
		NUM_CPUS=`cat /proc/cpuinfo | grep processor | wc -l`
	fi

	echo "Discovered ${NUM_CPUS}"

	if [ 1 -gt "${NUM_CPUS}" ]
	then
	       	NUM_CPUS=8
		echo "Could not automatically determine number of CPUs available, defaulting to ${NUM_CPUS}"
        fi
fi

echo "Number CPUs: ${NUM_CPUS}"


echo "SNPS_ALL=${SNPS_ALL}"
echo "GENBANKFILE=${GENBANKFILE}"
echo "CORE=${CORE}"
echo "ML=${ML}"
echo "NJ=${NJ}"
echo "VCF=${VCF}"
echo "DEBUG=${DEBUG}"


### Preprocess FASTA input file.

#chesk the fasta genome files to be sure line endings are Unix and fix if they are not
# Copy the original input file ${FASTA_LIST} to a specified name in the output directory for easier reference
cp -f "${FASTA_LIST}" fasta_list

# Process each file listed in the input file to correct the line endings if needed and if possible
"${LE2UNIX}" fasta_list

# Then process the fasta_list file to correct its line-endings.
perl -i -pe 's/\015\012/\012/g' fasta_list    # Windows to unix
perl -i -pe 's/\015/\012/g' fasta_list	      # Mac old format to unix



### Preprocess Annotation input file.

# WARNING:
# The file 'annotate_list' in the working / output directory is maintained state.
# This means different behavior if the output directory is re-used.
# WARNING

# Benefits to operating on a copy? (does this program modify 'annotate_list'
# file?) - JN
if [ -e "${ANNOTATE_LIST}" ]
then
	cp -f "${ANNOTATE_LIST}" annotate_list
else
	touch annotate_list
fi

# Which means that the conversion to unix line-endings needs to be redone...? - JN
#DOS to unix
perl -i -pe 's/\015\012/\012/g' annotate_list	# Windows to unix
perl -i -pe 's/\015/\012/g' annotate_list	# Mac old format to unix

# Output contents of annotate_list to the console (why?) - JN
echo "Finished genomes for finding SNP positions:"
cat annotate_list
echo ""


# Make lookup table of genome names and fsplit# files, and create fsplit# files by merging entries of multi-contig/multi-read input genomes. 
# Note that this is sensitive to extra lines, including blank lines?
NUM_SEQS=`wc -l fasta_list | awk '{print $1}' `

echo "Number of input sequences: ${NUM_SEQS}"

# Ensure fileName2genomeName file exists and is empty.
rm "${FILE2GENOME}" 2> /dev/null # Ignore errors
touch "${FILE2GENOME}"

# VAR


# Output fasta_list input file, with lines numbered from zero in the first column, and write
# a mapping from fsplit<line number> to genome name (tab separated) into fileName2genomeName
# file
COUNT=0
cat fasta_list | while read FILE GENOME   # Read the contents of each line into two variables.
do
    # Output to the screen the association between the count, the genome name and the file.
    echo "${COUNT}\t${GENOME}\t${FILE}"
    
    FSPLIT="${SPLITNAME}${COUNT}"
    # Combine multiple FASTA file records in a file into a single record by joining them with 'N'
    # NOTE: This can take measurable amount of time for FASTA files with lots of records.  Cache this data? - JN FXIME TODO XXX
    "${MERGE_FASTA_READ}" "${FILE}" > "${FSPLIT}"
    
    # Mapping of fsplit filename to genome
    echo "${FSPLIT}\t${GENOME}" >> "${FILE2GENOME}"
    
    # Increment count variable
    COUNT=`expr "${COUNT}" + 1`
done


#############
# FINISHED Setup of environment, update user re: details.
#############




#############
#############
#
# Run jellyfish on the merged input files to produce kmers list files.
#
#############
#############

# Input: List of merged input files (in the $FILE2GENOME file here) and the files themselves
# Output: A kmers_all version of each input file.


date # Output the date for timing info.
echo "Running jellyfish to find k-mers"

# Extract the names of the files from the list we already created, and iterate through the list.
cat "${FILE2GENOME}" | while read FILE REST
do
    KMERSALL="${KMERSALLPREFIX}.${FILE}"
    UNSORTEDKMERS="${UNSORTEDKMERSPREFIX}.${FILE}"
    if [ ! -s "${KMERSALL}" ]
    then
	JELLYFILE="Jelly.${FILE}"
	echo "${FILE}"  # Perhaps we should print the genome instead?  It is in $REST at this time

	# Extract all of the k-mers from the input fasta files ( along with counts? or is that just a placeholder? )
	"${JELLYFISH}" count -C -o "${JELLYFILE}" -m "${K}" -s "${HASHSIZE}" -t "${NUM_CPUS}" "${FILE}"

	# Output is not sorted.
	"${JELLYFISH}" dump -c "${JELLYFILE}" > "${UNSORTEDKMERS}"

	# Not clear that output needs to be sorted yet.
	sort "${UNSORTEDKMERS}" > "${KMERSALL}"
	
	# Note that we aren't removing the $JELLYFILE?  It is smaller than the origin file, to be fair.
	rm "${UNSORTEDKMERS}"
    fi
done

echo "Finished running jellyfish."


#############
# START Filtering k-mers from jellyfish based on frequency.
#############


### FIXME TODO XXX Removed portion of the kSNP3 tcsh script referencing 'sa' tool as unused.  It overlaps with jellyfish function above.

FREQUENCYPREFIX="freq"
KMERSPREFIX="kmers"

echo "Filtering out low-frequency kmers."

# Extract the names of the files from the list of input files we already created, and iterate through the list.
cat "${FILE2GENOME}" | while read FILE REST
do
    FREQUENCY="${FREQUENCYPREFIX}.${FILE}"
    KMERSALL="${KMERSALLPREFIX}.${FILE}"
    KMERS="${KMERSPREFIX}.${FILE}"

    awk '{print $2}' "${KMERSALL}" > "${FREQUENCY}"

    MIN_KMER_COVERAGE=`"${GETQUANTILE}" "${FREQUENCY}"`
    echo "minimum kmer coverage for ${FILE} is ${MIN_KMER_COVERAGE}"

    # Filter out k-mers with frequency lower than the $MIN_KMER_COVERAGE
    awk -v "m=${MIN_KMER_COVERAGE}" '$2>=m {print}' "${KMERSALL}" > "${KMERS}"

    # Remove temporary frequency file
    rm "${FREQUENCY}"
done

date
echo "Filtered out low-frequency kmers."

#############
# FINISHED Filtering k-mers from jellyfish based on frequency.
#############



#############
#
# START Remove conflicting k-mers.  A k-mer is conflicting there are multiple
# 'alleles' (k-mers matching in all but the center) within a given genome.
#
# This is an issue because you cannot discern a mutation between two genomes
# when there are multiple matching k-mers _within_ a genome using this tool
# which is restricted to looking at the k-mers without the full genome context.
#
#############

### Input: kmers.fsplit<N> (all)
### Output: Dir.fsplit<N>/X*.mers (many for each fsplit<N> source) 
### Output: kmers_fsplit<N>.conflictsDeleted (each)
### Transform: k-mers in the kmers.fsplit<N> file sorted into buckets of 
###   identical prefix
### Transform: A conflict is when a k-mer matches another in every character
###   except the center.  These are removed from the buckets of identical
###   prefix above, and the resulting k-mers are simply listed in the output
###   file (.conflictsDeleted) in sorted order.

# Challenges:
#  - Creates a lot of files that then need to be managed.
#  - Parallelizes without regard to size of dataset (confirm?)
#  - LOTS of sorting.


DIRPREFIX="Dir"
REMOVECONFLICTSCOMMANDS="cmds_remove_conflicting"

# Remove kmers from a genome if there are conflicting alleles in that genome 
echo "Removing conflicting kmers from each genome with conflicting alleles"

cat "${FILE2GENOME}" | while read FILE REST
do
    GENOMEDIRECTORY="${DIRPREFIX}.${FILE}"
    KMERS="../${KMERSPREFIX}.${FILE}"

    echo "${FILE}"
    mkdir "${GENOMEDIRECTORY}"
    cd "${GENOMEDIRECTORY}"

    "${SUBSETMERS}" "${KMERS}"

    rm "${REMOVECONFLICTSCOMMANDS}" 2> /dev/null
    touch "${REMOVECONFLICTSCOMMANDS}"

    # I think these are the output files from subset_mers3? TODO FIXME XXX
    # Note that this can use xargs v. easily.
    for SUBSET in *.mers     
    do
	# Remove conflicts, and place them in a new file with the suffix "conflictsDeleted"
	# The output filename should be explicit to make subsequent references clearer.
	echo "${DELETEALLELECONFLICTS} ${SUBSET}" >> "${REMOVECONFLICTSCOMMANDS}"
    done
    
    "${PARALLELCOMMANDS}" "${NUM_CPUS}" "${REMOVECONFLICTSCOMMANDS}"

    cd ..   # Return to the working directory.

done

echo "Finished removing conflicting kmers"
date

#############
#
# FINISHED Remove conflicting k-mers.
#
#############




echo "Merge sorted k-mer files and remove duplicates"
MERLIST="mer_list"
SORT_COMMANDS="cmds_sort"

"${SUBSETMERLIST}" > "${MERLIST}"

cat "${MERLIST}" | while read SUBSET
do
    echo "sort -m -u ${DIRPREFIX}.*/${SUBSET}.${CONFLICTSSUFFIX} > ${SUBSET}" >> "${SORT_COMMANDS}"
done

"${PARALLELCOMMANDS}" "${NUM_CPUS}" "${SORT_COMMANDS}"

echo "Finished merging k-mers across genomes."
date


#############
#
# START working with SNPs files
#
#############

SNPSALLSUFFIX="SNPs_all"
SNPLOCIPREFIX="SNP_loci"
SNPLOCISUFFIX="fasta"
PICKSNPCMDS="cmds_pick_snps"


#############
#
# START Generating loci per-bucket.
#
#############



if [ -e "${SNPS_ALL}" ]   # If the SNPs_all argument points to a file that exists... (cached answers)
then
    # There is some ambiguity in this case. Since we are using cached data, the SNPs in the SNPs_all file
    # may not correspond to the genomes in the $FASTA_LIST input file.  Is that okay?  Should we 1) confirm,
    # or 2) do something different if we have different input genomes?
    echo "Using existing SNPs from ${SNPS_ALL} file"
    date

    # Requires $SNPS_ALL file to be sorted.  Create <prefix>.mers.SNPs_all files for each prefix that could exist, empty if not found in $SNPS_ALL
    # For prefixes found in $SNPS_ALL, fill the corresponding file with lines matching the prefix from $SNPS_ALL.
    "${SUBSETSNPSALL}" "${SNPS_ALL}"
    cat "${MERLIST}" | while read SUBSET # For each k-mer prefix bucket....
    do
	SUBSETSNPS="${SUBSET}.${SNPSALLSUFFIX}"
	SUBSETLOCI="${SNPLOCIPREFIX}.${SUBSET}.${SNPLOCISUFFIX}"

	if [ -s "${SUBSETSNPS}" ] # If the subset SNPs file exists and is non-zero size...
	then
	    # Create a fasta-like file labeled with locus (k-mer without the nucleotide in the middle) followed by the allele identifier (nucleotide that would go in the middle)
	    # The contents of that FASTA entry is the sequence (first half, period, middle nucleotide, period second half?  Perhaps the period is a concatenation operator?)
	    # These entries are sorted first by locus, then by allele identifier, and are implicitly deduped by being written / overwritten into a dict and then pulled out.
	    "${SNPSTOFASTAQUERY}" "${SUBSETSNPS}" > "${SUBSETLOCI}"
	fi
    done
    
else # SNPs_all argument did NOT point to a file that exists....
	# do all the SNP finding
	echo "Discovering new SNPs"
	date
	
	echo "Finding kmers with multiple allele variants"


	cat "${MERLIST}" | while read SUBSET # For each k-mer prefix bucket....
	do
	    SUBSETLOCI="${SNPLOCIPREFIX}.${SUBSET}.${SNPLOCISUFFIX}"

	    # Note that $PICKSNPSFROMKMERS assumes a sorted input which is a bucket of filtered k-mers from all genomes with a common prefix.  It was sorted above.
	    # This will filter out k-mers that don't have a SNP, and for those that do, prints
	    # all of the polymorphisms in a fasta-like file that is labeled with the locus (k-mer with the nucleotide in the center replaced with a period), followed by
	    # an underscore, then the nucleotide that was in the center (allele identifier), with the contents of the entry being the sequence itself (no period separation)
	    # The output is sorted on locus and NOT sorted on allele identifier.  This output is put into a corresponding bucket named to indicate that it contains loci.
	    echo "${PICKSNPSFROMKMERS} ${SUBSET} > ${SUBSETLOCI}" >> "${PICKSNPCMDS}"
	done
	
	"${PARALLELCOMMANDS}" "${NUM_CPUS}" "${PICKSNPCMDS}"

	echo "Finished finding kmers with multiple allele variants"
fi


 # Find which genome has which allele variant, by comparing the SNP_loci and Dir.$f/$subset.conflictsDeleted  foreach genome
date



echo "Finding allele in each genome"
rm "${FINDALLELECMDS}" 2> /dev/null
touch "${FINDALLELECMDS}"

cat "${FILE2GENOME}" | while read FILE REST  # For each genome input file...
do
    GENOMEDIRECTORY="${DIRPREFIX}.${FILE}"

    cat "${MERLIST}" | while read SUBSET # For each k-mer prefix bucket....
    do
	# All "loci" (k-mer missing center nucleotide) that share a prefix / in a prefix-based bucket.
	SUBSETLOCI="${SNPLOCIPREFIX}.${SUBSET}.${SNPLOCISUFFIX}"

	#### COMMENT GOES HERE (figure out what this does)
	# Take the combined loci found to be interesting (overlaps with different alleles amongst genomes), and the set of alleles filtered from the original genome
	# (in ${GENOMEDIRECTORY}/${SUBSET}.${CONFLICTSDELETED}), and the original original genome file (${FILE}) and combine them into a tab
	# separated list of the locus (k-mer context around the SNP), the allele (missing nucleotide), the original nucleotide sequence (redundant from the first two
	# columns), and the filename containing the original genome. (just the filename)
	# Put the result in SNPs.<bucket> in the ${GENOMEDIRECTORY}.
	# This can maybe be done with 'grep', i.e. grep -f locifile conflictsoutput ?
	echo "${FINDALLELE} ${SUBSETLOCI} ${GENOMEDIRECTORY}/${SUBSET}.${CONFLICTSSUFFIX} ${FILE} > ${GENOMEDIRECTORY}/${SNPSPREFIX}.${SUBSET}" >> "${FINDALLELECMDS}"
    done
done

"${PARALLELCOMMANDS}" "${NUM_CPUS}" "${FINDALLELECMDS}"


cat "${FILE2GENOME}" | while read FILE REST  # For each genome input file...
do
    GENOMEDIRECTORY="${DIRPREFIX}.${FILE}"
    
    # Combine all of the bucketed SNPs into a single file of SNPs per-genome.
    cat "${GENOMEDIRECTORY}/${SNPSPREFIX}."*".${MERSSUFFIX}" > "${GENOMEDIRECTORY}/${SNPSPREFIX}"
done


#############
#
# FINISHED Generating loci per-bucket.
#
#############





# Run mummer to find the position of each SNP in the finished genomes. Don't do this for unassembled draft genomes or merged raw read genomes, since positional information is not informative.


if [ -s "${ANNOTATE_LIST}" ]
then
	echo "Finding SNP positions in finished genomes using mummer."
	date

	rm "${MUMMERCMDS}" "${PARSEMUMMERCMDS}" 2> /dev/null
	touch "${MUMMERCMDS}" "${PARSEMUMMERCMDS}"

	cat "${ANNOTATE_LIST}" | while read GENOME
	do
	    TEST=`grep -w "${GENOME}" "${FILE2GENOME}" | wc -l`
	    FILE=`grep -w "${GENOME}" "${FILE2GENOME}" | awk '{print $1}'`
	    GENOMEDIRECTORY="${DIRPREFIX}.${FILE}"

	    if [ 0 -lt "${TEST}" ]
	    then

		GENOMEFILE=`grep -w "${GENOME}" "${FASTA_LIST}" | awk -F'\011' '{print $1}'`
		echo "genome: ${GENOME} in ${GENOMEDIRECTORY}"

		# What does this do??  Assign filename to a meaningfully named variable rather than creating it twice.
		# This turns a list of SNPs (e.g. the SNPs file per-genome) into a fasta-type file for input to mummer
		SNPSINFASTAFORMAT="${GENOMEDIRECTORY}/${SNPSPREFIX}.${SNPLOCISUFFIX}"
		awk -F'\011' '{print ">" $1 "_" $2 "\n" $3 }' "${GENOMEDIRECTORY}/${SNPSPREFIX}" > "${SNPSINFASTAFORMAT}"

		# These two commands output the SNP positions data.
		# Mummer takes the per-SNP (loci + specific nucleotide) labeled list of interesting k-mers, and finds where they are
		# in the original genome(s).  The output is loci with a . replacing the differing nucleotide, an underscore, and the nucleotide
		# that was in the middle.
		echo "${MUMMER} -maxmatch -l ${K} -b -c ${SNPSINFASTAFORMAT} ${GENOMEFILE} > ${GENOMEDIRECTORY}/${MUMMEROUTPUT}" >> "${MUMMERCMDS}"
		# This is strictly a basic line-by-line parsing of mummer output; could / should be in a pipeline, as it is v. low
		# complexity and would avoid writing the mummer output to disk before parsing.
		echo "${PARSEMUMMER} ${GENOMEDIRECTORY}/${MUMMEROUTPUT} > ${GENOMEDIRECTORY}/${SNPPOSITIONS}" >> "${PARSEMUMMERCMDS}"

	    fi
	done

	# Mummer is capable of running in sequence on multiple "query" files (i.e. $GENOMEFILE). I suspect we aren't doing this
	# so that we can parallelize the processes.  Also, bucket size has an impact on mummer memory use.
	"${PARALLELCOMMANDS}" "${NUM_CPUS}" "${MUMMERCMDS}"
	"${PARALLELCOMMANDS}" "${NUM_CPUS}" "${PARSEMUMMERCMDS}"

	date
	echo "Finished finding SNP positions in finished genomes using mummer."
fi



#############
#############
#
# kSNP rewrite in Bash / Bourne shell stops here.
#
#############
#############





ALLSNPSUNSORTED="all_SNPs_unsorted"
ALLSNPSSORTED="all_SNPs_sorted"

touch "${ALLSNPSUNSORTED}"

cat "${FILE2GENOME}" | while read FILE GENOME  # For each genome input file...
do
    GENOMEDIRECTORY="${DIRPREFIX}.${FILE}"
    echo "genome: ${GENOME} in ${GENOMEDIRECTORY}"
    
    POSITIONSFILE="${GENOMEDIRECTORY}/${SNPPOSITIONS}"
    SNPSFILE="${GENOMEDIRECTORY}/${SNPSPREFIX}"
    
    if [ -s "${POSITIONSFILE}" ]  # We can create the full SNPs data that references locations in the original genome.
    then 
	awk -F'\011' -v "f=${FILE}" '{print $1 "\t" $2 "\t" $3  "\t" f "\t" $4}' "${POSITIONSFILE}"  >> "${ALLSNPSUNSORTED}"
    else   # mummer failed.... (we should output something here?)
	# Output SNP data, though we don't have location and direction info, and for some reason we put the genome name
	# where the file name should go ???  (we have both genome name and filename, so that's weird, right?)
	# We can get a lot of the same mapping (filename, ascension number, genome name) from non-mummer info, so this
	# seems weak sauce.  Also the output is v. different in terms of the k-mers / SNPs that show up (it seems).
	# TODO FIXME XXX not sure what's going on here.
	echo "Warning, mummer output missing!"
	awk -v "genome=${GENOME}" '{print  $1 "\t" $2 "\tx\t" genome "\t" }' "${SNPSFILE}" >> "${ALLSNPSUNSORTED}"
    fi
done

### Now we have unsorted SNP data from all genomes in one file.


if [ -e "${SNPS_ALL}" ] # If we have prior SNPs data...
then
    # Add all of the $SNPS_ALL file to the end of the unsorted SNPs data, omitting the first column
    # which is the count.
    awk -F'\011'  '{print $2 "\t" $3 "\t" $4  "\t" $5 "\t" $6 "\t" $7}' "${SNPS_ALL}" >> "${ALLSNPSUNSORTED}"
fi

# Sort the resulting SNPs file.
sort -u "${ALLSNPSUNSORTED}" > "${ALLSNPSSORTED}"


ALLSNPSSORTEDLABELED="all_SNPs_sorted_labelLoci"

# Create a unique number for each distinct loci, separates loci by blank line.
# Outputs to all_SNPs_sorted_labelLoci
"${NUMBERSNPS}" "${ALLSNPSSORTED}"

SNPSALLOUTPUT="SNPs_all"

"${RENAMEFROMTABLE}" "${ALLSNPSSORTEDLABELED}" "${FILE2GENOME}" "${SNPSALLOUTPUT}"



# Set reference genome for vcf file to the be first finished genome, if this is empty, then set it to be the first genome in the input fasta file.
if [ -s "${ANNOTATE_LIST}" ]
then
    REFERENCEGENOME=`head -1 annotate_list`
else
    REFERENCEGENOME=`head -1 fileName2genomeName | awk '{print $2}'`
fi

VCFFILE="VCF.${REFERENCEGENOME}.vcf"

if [ 1 -eq "${VCF}" ] # If -vcf flag was passed to kSNP, parse the SNPs_all file.
then
    # Bug where this invocation has error: "Cannot open all" - FIXME TODO XXX - JN
   "${PARSESNPSTOVCF}" "${SNPSALLOUTPUT}" "${VCFFILE}" "${REFERENCEGENOME}"
fi

echo "Finished finding SNPs"
date


SNPSMATRIX="SNPs_all_matrix"
SNPSMATRIXFASTA="${SNPSMATRIX}.${SNPLOCISUFFIX}"


## Create a SNP matrix and fasta, for inputting to PHYLIP, FastTreeMP or other tools like SplitsTree
"${SNPSTOFASTAMATRIX}" "${SNPSALLOUTPUT}" "${SNPSMATRIXFASTA}" "${SNPSMATRIX}"

# This variable is used to record and then retrieve which types of trees are made from the list:
# parsimony, nj and ml.
TREELISTONE="tree_list1"
TREELISTTWO="tree_list2" # Probably unused

# Shortcut to put the same data in two files.
echo "parsimony" | tee "${TREELISTONE}" > "${TREELISTTWO}"

############### Make tree using SNP matrix
echo "Building parsimony tree"

# Build parsimony tree
# From _the_source_code_ (axml.c, get_args()):
# (side note, filenames are limited to 1k characters.  possibility of overflow here, yay C!)
#  -s <sequence file> (no info on file format here)
#  -p <parsimony seed> (used for randomness?!??)
#  -n <runID>  (Causes run <runID> to be analyzed.  Output data is put into two files: RAxML_parsimonyTree.<runID> and RAxML_info.<info>)
#  -N <number of trees> (Number of parsimony trees to compute)
"${PARSIMONATOR}" -s "${SNPSMATRIX}" -n "${SNPSALLOUTPUT}" -N "${NUMTREES}" -p "${PARSIMONYSEED}"

PARSIMONATORINFO="RAxML_info.${SNPSALLOUTPUT}"
PARSIMONATORTREE="RAxML_parsimonyTree.${SNPSALLOUTPUT}"
# Next we parse the output of $PARSIMONATOR to report on the generated trees.

INTREE="intree"

BESTPARSIMONYSCORE=`grep "Parsimony tree" RAxML_info.SNPs_all | sort -k6 -n | head -1 | awk '{print $6}'`
# Create a list of the best parsimony trees in $INFILE
grep "Parsimony tree" "${PARSIMONATORINFO}" | awk -v "score=${BESTPARSIMONYSCORE}" '$6==score {print $14}' > "${INTREE}"
NUMBESTPARSIMONYTREES=`cat "${INTREE}" | wc -l | awk '{print $1}'`
printf "Number of most parsimonious trees from SNPs_all: ${NUMBESTPARSIMONYTREES}"
printf "Score of those trees: ${BESTPARSIMONYSCORE}"

exit 0


# Get majority consensus tree
rm outfile outtree
#PHYLIP consense was the only tool i found  that forced resolution of every branch. FastTree to give it branch lengths will crash if some notes have splits to >2 children. But you need to modify seq.h and phylip.h before compiling consense to allow longer names so they don't get truncated
echo "Y\n" | $kSNP/consense

# Give it branch lengths, optimized for the consensus parsimony tree.
# Input to force_binary_tree is one tree per file.
$kSNP/force_binary_tree outtree outtree.resolved
$kSNP/FastTreeMP -nt -pseudo   -nome -mllen -gamma -gtr -intree outtree.resolved SNPs_all_matrix.fasta >! tree.parsimony.tre
mv RAxML* TemporaryFilesToDelete/.










$kSNP/rename_from_table3 all_SNPs_sorted_labelLoci fileName2genomeName SNPs_all


# Set reference genome for vcf file to the be first finished genome, if this is empty, then set it to be the first genome in the input fasta file.
if (-s annotate_list) then
	set ref_genome=`head -1 annotate_list`
endif
if !($?ref_genome) then
	set ref_genome=`head -1 fileName2genomeName | awk '{print $2}'`
endif

# Did not review this path due to not executing in Run1.  TODO - JN
if ($?vcf ) then
	$kSNP/parse_SNPs2VCF3 SNPs_all VCF.$ref_genome.vcf  $ref_genome
endif

echo "Finished finding SNPs"
date


# Suggest prompting user to delete the temporary files directory if the run was
# successful?  Also suggest having a unique temporary directory for each run
# instead of deleting the previous temporary directory automatically. - JN


# You can delete this Directory if everything works, but it's useful for debugging in case the run fails
rm -r TemporaryFilesToDelete
mkdir TemporaryFilesToDelete
mv -f Dir.* TemporaryFilesToDelete/.
if (-e cmds_mummer) then 
	mv -f cmds_mummer TemporaryFilesToDelete/.
	mv -f cmds_parse_mummer TemporaryFilesToDelete/.
endif
mv -f  *.mers TemporaryFilesToDelete/.
mv -f Jelly.* TemporaryFilesToDelete/.
mv -f SNP_loci.*.mers.fasta TemporaryFilesToDelete/.
mv -f kmers*  TemporaryFilesToDelete/.
mv -f fsplit* TemporaryFilesToDelete/.
mv -f  all_SNPs_unsorted  TemporaryFilesToDelete/.
mv -f  all_SNPs_sorted* TemporaryFilesToDelete/.
mv -f mer_list TemporaryFilesToDelete/.
mv -f *.mers.SNPs_all TemporaryFilesToDelete/.


##probes_from_SNPs_all_kmers $probe_prefix_label

## Create a SNP matrix and fasta, for inputting to PHYLIP, FastTreeMP or other tools like SplitsTree
$kSNP/SNPs_all_2_fasta_matrix3 SNPs_all SNPs_all_matrix.fasta SNPs_all_matrix

printf "parsimony\n" >! tree_list1
printf "parsimony\n" >! tree_list2

############### Make tree using SNP matrix
echo "Building parsimony tree"

# Build parsimony tree
$kSNP/parsimonator -s SNPs_all_matrix -n SNPs_all -N 100 -p 1234

# get all the best scoring trees
# Note: Score == length. - JN
set best_parsimony_tree_score=`grep "Parsimony tree" RAxML_info.SNPs_all | sort -k6 -n | head -1 | awk '{print $6}'`
set best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_all | awk -v score=$best_parsimony_tree_score '$6==score {print $14}'`
set Num_best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_all | awk -v score=$best_parsimony_tree_score '$6==score {print $14}' | wc -l | awk '{print $1}'`
printf "Number of most parsimonious trees from SNPs_all: $Num_best_parsimony_trees\n"
printf "Score of those trees: $best_parsimony_tree_score\n"

cat $best_parsimony_trees >! intree

# Get majority consensus tree
rm outfile outtree
#PHYLIP consense was the only tool i found  that forced resolution of every branch. FastTree to give it branch lengths will crash if some notes have splits to >2 children. But you need to modify seq.h and phylip.h before compiling consense to allow longer names so they don't get truncated
echo "Y\n" | $kSNP/consense

# Give it branch lengths, optimized for the consensus parsimony tree.
# Input to force_binary_tree is one tree per file.
$kSNP/force_binary_tree outtree outtree.resolved
$kSNP/FastTreeMP -nt -pseudo   -nome -mllen -gamma -gtr -intree outtree.resolved SNPs_all_matrix.fasta >! tree.parsimony.tre
mv RAxML* TemporaryFilesToDelete/.


### This section does similar to above section, except for different input file
### SNPs_all has been replaced by SNPs_in_majorit<min_fraction_with_locus> ...
### The above should maybe be proceduralized to reduce code repetition?
###  - JN


###
###  BEGIN TEST ALPHA
###
###  This starts a long conditional ending in a loop far below, also marked
###  with label above (except END).
###


## Build parsimony tree from SNPs_in_majority"$min_fraction_with_locus"
if ($?min_fraction_with_locus) then 
	printf "Getting SNPs_in_majority$min_fraction_with_locus and building tree\n"
	$kSNP/core_SNPs3 SNPs_all fileName2genomeName $min_fraction_with_locus
	$kSNP/SNPs_all_2_fasta_matrix3 SNPs_in_majority"$min_fraction_with_locus"  SNPs_in_majority"$min_fraction_with_locus"_matrix.fasta SNPs_in_majority"$min_fraction_with_locus"_matrix

	# Build parsimony tree
	# Not sure what arguments are here.  -N appears to be # of trees to generate?
	# It is definitely associated with # of files to generate (0 - N-1)
	$kSNP/parsimonator -s SNPs_in_majority"$min_fraction_with_locus"_matrix -n SNPs_majority"$min_fraction_with_locus" -N 100 -p 1234

	# get all the best scoring trees
	# Find the best score...
	set best_parsimony_tree_score=`grep "Parsimony tree" RAxML_info.SNPs_majority"$min_fraction_with_locus" | sort -k6 -n | head -1 | awk '{print $6}'`
	# Grab the elements with the best score...
	set best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_majority"$min_fraction_with_locus" | awk -v score=$best_parsimony_tree_score '$6==score {print $14}'`
	# Finally, count how many elements we grabbed.
	set Num_best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_majority"$min_fraction_with_locus" | awk -v score=$best_parsimony_tree_score '$6==score {print $14}' | wc -l | awk '{print $1}'`

	# Output a summary to user.
	printf "Number of most parsimonious trees for SNPs_in_majority$min_fraction_with_locus : $Num_best_parsimony_trees\n"
	printf "Score of those trees: $best_parsimony_tree_score\n"


	cat $best_parsimony_trees >! intree

	# Get majority consensus tree
	rm outfile outtree
	#Find consensus parsimony tree
	echo "Y\n" | $kSNP/consense

	# Give it branch lengths, optimized for the consensus parsimony tree.
	# Script making use of biology related perl modules - JN
	$kSNP/force_binary_tree outtree outtree.resolved
	# Multiprocessing software. - JN
	$kSNP/FastTreeMP -nt -pseudo   -nome -mllen -gamma -gtr -intree outtree.resolved SNPs_in_majority"$min_fraction_with_locus"_matrix.fasta  >! tree.majority"$min_fraction_with_locus".tre
	mv RAxML* TemporaryFilesToDelete/.


	# The below takes away -nome -mllen -intree.  Look up what that changes, try to figure out why? - JN

	# Uncomment the following line to build ML majority tree, and write over the parsimony majority tree just built
	#$kSNP/FastTreeMP  -nt -pseudo  -gamma   -gtr SNPs_in_majority"$min_fraction_with_locus"_matrix.fasta  >!  tree.majority"$min_fraction_with_locus".tre


	# Can this loop execute more than once?  Why a foreach? - JN
	foreach t (  majority"$min_fraction_with_locus" )
		$kSNP/label_tree_nodes3 tree.$t.tre   > ! tree_nodeLabel.$t.tre
		$kSNP/tree_nodes3 tree_nodeLabel."$t".tre  nodes.$t
		if (-s tree_nodeLabel.$t.tre ) then
			echo "Placing SNPs on nodes $t tree"
			$kSNP/SNPs2nodes-new3 SNPs_in_majority"$min_fraction_with_locus"  nodes.$t.perlhash tree_nodeLabel.$t.tre  Node_SNP_counts.$t
			if (-e COUNT_Homoplastic_SNPs) then
				mv COUNT_Homoplastic_SNPs COUNT_Homoplastic_SNPs.$t
			endif
			if (-e ClusterInfo) then
				mv ClusterInfo ClusterInfo.$t
			endif
			if (-e Homoplasy_groups) then
				mv Homoplasy_groups Homoplasy_groups.$t
			endif
			date
			echo "Finished placing SNPs on nodes $t tree"
			printf "name_on_tree\tSNP_counts\n" >! tip_SNP_counts.$t
			grep "node: " Node_SNP_counts.$t | grep -w "NumberTargets: 1" | awk '{print $2 "\011" $6}' >> tip_SNP_counts.$t

			if (-s tree_nodeLabel.$t.tre.rerooted) then
				rm -f tree_nodeLabel.$t.tre
				mv -f tree_nodeLabel.$t.tre.rerooted tree_nodeLabel.$t.tre
			endif

			#rm_node_names_from_tree tree_nodeLabel.$t.tre tree.$t.tre # don't overwrite tree.$t.tre anymore since we want the support values in original file.

			$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.tre tree_AlleleCounts.$t.tre 0
			$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.NodeLabel.tre tree_AlleleCounts.$t.NodeLabel.tre 1

		endif
	end
endif

###
###  END TEST ALPHA
###


# Note that there seems to be at least some duplication from conditional above. - JN
# At some point take a thorough look to compare, and then factor out the
# differences to make it easier to understand.
#

###
###  START TEST BETA
###
###  This starts a long conditional ending in a loop far below, also marked
###  with label above (except END).
###

##Building parsimony tree from only the core SNPs
if ($?core) then 
	printf "Getting core SNPs"
	if (! $?min_fraction_with_locus) then
		$kSNP/core_SNPs3 SNPs_all fileName2genomeName 0.5
	endif
	$kSNP/SNPs_all_2_fasta_matrix3 core_SNPs core_SNPs_matrix.fasta core_SNPs_matrix

	# Build parsimony tree
	$kSNP/parsimonator -s core_SNPs_matrix  -n SNPs_core -N 100 -p 1234

	# get all the best scoring trees
	set best_parsimony_tree_score=`grep "Parsimony tree" RAxML_info.SNPs_core | sort -k6 -n | head -1 | awk '{print $6}'`
	set best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_core | awk -v score=$best_parsimony_tree_score '$6==score {print $14}'`

	set Num_best_parsimony_trees=`grep "Parsimony tree" RAxML_info.SNPs_core | awk -v score=$best_parsimony_tree_score '$6==score {print $14}' | wc -l | awk '{print $1}'`

	printf "Number of most parsimonious trees for SNPs_core : $Num_best_parsimony_trees\n"
	printf "Score of those trees: $best_parsimony_tree_score\n"


	cat $best_parsimony_trees >! intree

	# Get majority consensus tree
	rm outfile outtree
	#Find consensus parsimony tree
	echo "Y\n" | $kSNP/consense

	# Give it branch lengths, optimized for the consensus parsimony tree.
	$kSNP/force_binary_tree outtree outtree.resolved
	$kSNP/FastTreeMP -nt -pseudo   -nome -mllen -gamma -gtr -intree outtree.resolved core_SNPs_matrix.fasta  >! tree.core.tre
	mv RAxML* TemporaryFilesToDelete/.

	# Uncomment the following line to build ML core tree, and write over the parsimony core tree just built
	#  $kSNP/FastTreeMP -nt  -gamma   -gtr core_SNPs_matrix.fasta  >!  tree.core.tre

	if (-s core_SNPs) then
		foreach t (  core )
			$kSNP/label_tree_nodes3 tree.$t.tre   > ! tree_nodeLabel.$t.tre
			$kSNP/tree_nodes3 tree_nodeLabel."$t".tre  nodes.$t
			if (-s tree_nodeLabel.$t.tre ) then
				echo "Placing SNPs on nodes $t tree"
				$kSNP/SNPs2nodes-new3 core_SNPs nodes.$t.perlhash tree_nodeLabel.$t.tre  Node_SNP_counts.$t
				if (-e COUNT_Homoplastic_SNPs) then
					mv COUNT_Homoplastic_SNPs COUNT_Homoplastic_SNPs.$t
				endif
				if (-e ClusterInfo) then
					mv ClusterInfo ClusterInfo.$t
				endif
				if (-e Homoplasy_groups) then
					mv Homoplasy_groups Homoplasy_groups.$t
				endif
				date
				echo "Finished placing SNPs on nodes $t tree"
				echo ""
				printf "name_on_tree\tSNP_counts\n" >! tip_SNP_counts.$t
				grep "node: " Node_SNP_counts.$t | grep -w "NumberTargets: 1" | awk '{print $2 "\011" $6}' >> tip_SNP_counts.$t

				if (-s tree_nodeLabel.$t.tre.rerooted) then
					rm -f tree_nodeLabel.$t.tre
					mv -f tree_nodeLabel.$t.tre.rerooted tree_nodeLabel.$t.tre
				endif

				#rm_node_names_from_tree tree_nodeLabel.$t.tre tree.$t.tre # don't overwrite tree.$t.tre anymore since we want the support values in original file.

				$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.tre tree_AlleleCounts.$t.tre 0
				$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.NodeLabel.tre tree_AlleleCounts.$t.NodeLabel.tre 1

			endif
		end
	endif
endif

## Building ML FastTree tree from all SNPs
if ($?ML) then
	$kSNP/FastTreeMP  -nt -pseudo  -gamma -gtr SNPs_all_matrix.fasta >!  tree.ML.tre
	printf "ML\n" >> tree_list1
	printf "ML\n" >> tree_list2
endif


if ( $?nj) then
	echo "Building NJ tree"
	date
	# NOTE:  This next line can take a long time if there are million+ SNP loci and 100+ genomes. SNP_matrix2dist_matrix does loops, so it's slow, should be parallelized.  Probably should try the PHYLIP program, although scores might be different since i count them as somewhat closer if they share a locus but not the allele than if they don't even share the locus. But since NJ SNP trees are not accurate anyway, i'm not inclined to spend anymore time since no one should use this option.
	# Above seems clear - JN
	$kSNP/SNP_matrix2dist_matrix3 SNPs_all_matrix >! NJ.dist.matrix
	$kSNP/distance_tree3 >! tree.NJ.tre
	echo "Finished building NJ tree"
	printf "NJ\n" >> tree_list1
	printf "NJ\n" >> tree_list2
	date
endif

#######################
 
$kSNP/find_unresolved_clusters3 tree.parsimony.tre >! unresolved_clusters

date
echo "Finding nodes"

foreach t ( `cat tree_list1` ) 
	if (-s tree."$t".tre) then
		# Opportunity to make this a subroutine?
		$kSNP/label_tree_nodes3 tree.$t.tre   > ! tree_nodeLabel.$t.tre
		$kSNP/tree_nodes3 tree_nodeLabel."$t".tre  nodes.$t
		echo "Placing SNPs on nodes $t tree"
		$kSNP/SNPs2nodes-new3 SNPs_all nodes.$t.perlhash tree_nodeLabel.$t.tre  Node_SNP_counts.$t
		if (-e COUNT_Homoplastic_SNPs) then
			mv COUNT_Homoplastic_SNPs COUNT_Homoplastic_SNPs.$t
		endif
		if (-e ClusterInfo) then
			mv ClusterInfo ClusterInfo.$t
		endif
		if (-e Homoplasy_groups) then
			mv Homoplasy_groups Homoplasy_groups.$t
		endif
		date
		echo "Finished placing SNPs on nodes $t tree"
		echo ""
	endif
end


# Relabel trees with SNP counts at nodes
foreach t (  `cat tree_list1` ) 
	if (-s tree."$t".tre) then

		printf "name_on_tree\tSNP_counts\n" >! tip_SNP_counts.$t
		grep "node: " Node_SNP_counts.$t | grep -w "NumberTargets: 1" | awk '{print $2 "\011" $6}' >> tip_SNP_counts.$t

		if (-s tree_nodeLabel.$t.tre.rerooted) then
			rm -f tree_nodeLabel.$t.tre
			mv -f tree_nodeLabel.$t.tre.rerooted tree_nodeLabel.$t.tre
		endif

		#rm_node_names_from_tree tree_nodeLabel.$t.tre tree.$t.tre # don't overwrite tree.$t.tre anymore since we want the support values in original file.

		$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.tre tree_AlleleCounts.$t.tre 0
		$kSNP/labelTree_AlleleCount-new3  tree_nodeLabel.$t.tre Node_SNP_counts.$t tree_tipAlleleCounts.$t.NodeLabel.tre tree_AlleleCounts.$t.NodeLabel.tre 1
	endif
end

mv -f nodes.* TemporaryFilesToDelete/.
mv -f tree_tipAlleleCounts.*.NodeLabel.tre TemporaryFilesToDelete/.
mv -f tree_nodeLabel.* TemporaryFilesToDelete/.

########
# find proteins where SNPs land, codons, amino acids, and identify nonsynonymous SNPs
echo "Annotating SNPs."
date

# Only get genbank file and annoate if there is positional information for some genomes, ie. annotate_list is not empty
if (-s annotate_list) then 

	# Get whole genome annotations from genbank, unfortunately you have to get the whole genbank file with sequence data, since the much smaller feature table does not have mature peptides making viral annotation useless with polyproteins only.
	set count=0
	printf "" >! headers.annotate_list
	foreach genome (`cat annotate_list`) 
		set file_check=`grep -w  $genome fasta_list  | wc -l`
		if ($file_check > 0 ) then
			set file=`grep -w  $genome fasta_list  | awk -F'\011' '{print $1}'`
			printf "$file\n"
			$kSNP/get_genbank_file3 "$file" genbank_from_NCBI.gbk.$count
			fgrep ">" "$file" | sed -e "s/^>/>$genome /" >> headers.annotate_list
			@ count ++
		endif
	end
	cat genbank_from_NCBI.gbk.* | grep -v BioProject  >! genbank_from_NCBI.gbk
	rm genbank_from_NCBI.gbk.*


	# The annotate_SNPs_from_genbankFiles3 is a complicated script; deserves review / commenting. TODO - JN
	if (-e "$genbankFile" ) then 
		$kSNP/annotate_SNPs_from_genbankFiles3   -all $all_annotations  $genbankFile
	else
		$kSNP/annotate_SNPs_from_genbankFiles3   -all $all_annotations 
	endif

	printf "Num_NotAnnotatedRegion\tAnnotatedNotProtein\tNum_NonSynon\tNum_Synon\tNS/S\tNSfractionOfAnnotated\tNumLoci\tNum_InAnnotatedGenomes\tNum_NotInAnnotatedGenome\n" >! Annotation_summary
	set i=SNP_annotations
	set num_notInAnnotatedGenome=`grep  NotInAnnotatedGenome $i |  awk '  {print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set num_UnAnnRegion=`grep  UnannotatedRegion $i |  awk '  {print $1}' | sort -u | wc -l | awk '{print $1}'`  
	set num_AnnNotProtein=`grep  NotProteinCoding $i |  awk '  {print $1}' | sort -u | wc -l | awk '{print $1}'`  

	set NS_total=`grep -v LocusNum $i |  awk ' $3>0 {print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set Num_loci=`grep -v LocusNum $i |  awk '{print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set Num_loci_in_annotated=`grep -v LocusNum $i | grep -v  NotInAnnotatedGenome |  awk '{print $1}' | sort -u | wc -l | awk '{print $1}'` 
	set S_total=`perl -e "print ($Num_loci_in_annotated-$NS_total)"`
	if ($S_total > 0) then
		set NS_Sratio=`perl -e "print $NS_total/$S_total"`
	else
		set NS_Sratio="inf"
	endif
	if ($Num_loci_in_annotated > 0) then 
		set NSfraction_overall=`perl -e "print $NS_total/$Num_loci_in_annotated"`
	else
		set NSfraction_overall="inf"
	endif

	printf "$num_UnAnnRegion\t$num_AnnNotProtein\t$NS_total\t$S_total\t$NS_Sratio\t$NSfraction_overall\t$Num_loci\t$Num_loci_in_annotated\t$num_notInAnnotatedGenome\n"  >> Annotation_summary


	$kSNP/parse_protein_annotation_counts3 SNP_annotations >!  Protein_Annotation_counts

	echo "Finished SNP annotation."
endif

# ParAnn is the compiled version of ParAnn.py, presumably.  Should be verified,
# and the process for compiling should be determined.  Once this is understood,
# perhaps a makefile for the binaries?  TODO - JN
#run ParAnn
$kSNP/ParAnn

echo "Finished running kSNP"
date
set endseconds=`date +%s`
set elapsedTime=`perl -e "print (($endseconds-$startseconds)/60/60)"`
echo "Elapsed time for kSNP in hours: $elapsedTime"


mv cmds* TemporaryFilesToDelete/.
mv tree_list1 TemporaryFilesToDelete/.
mv tree_list2 TemporaryFilesToDelete/.
mv -f fileName2genomeName TemporaryFilesToDelete/.
rm intree outtree outfile
rm SNP_annotations

if (-s SNPs_all && -s tree.parsimony.tre && -s tree_AlleleCounts.parsimony.tre && -s unresolved_clusters && -s COUNT_SNPs && $DEBUG<1) then
	rm -r TemporaryFilesToDelete
endif

exit

###
### Code after this section is preserved history, not live. - JN
###



##########################################################################################################
##########################################################################################################

# HRE finder is not updated to work with kSNP3.  Use kSNP2 if you want to use HREfinder.
#  In case you want to run HREFinder  at http://sourceforge.net/projects/hrefinder/ 
# set your path to the hreFinder code  "set hre=/path/to/hreFinder"
# and comment out the exit line above.
# YOU MUST HAVE ALL THE GENOMES IN THE -p annotate_list LIST. FOR HREFINDER YOU NEED POSITIONAL 
# INFORMATION FOR ALL OF THEM, EVEN THE DRAFT GENOMES THAT ARE ASSEMBLED INTO A FEW LARGE CONTIGS. 
# If some draft genomes are in alot of contigs, it is recommended that
# you remove those and rerun kSNP before attempting hreFinder. 
# Don't run hreFinder with genomes that are raw unassembled reads.


###### Run hreFinder to predict series of SNPs likely to have been involved in homologous recombination events

set hre=/usr/gapps/kpath/hreFinder   


if (-s SNPs_all) then

# Set reference genome for vcf file to the be first finished genome, if this is empty, then set it to be the first genome in the input fasta file.
if (-s annotate_list) then
    set ref_genome=`head -1 annotate_list`
endif
if !($?ref_genome) then
    set ref_genome=`head -1 fileName2genomeName | awk '{print $2}'`
endif


foreach tree (`cat tree_list2`)
mkdir  HRE.$tree
cd HRE.$tree
$hre/run_config.py ../tree.$tree.tre    ../fastainput ../SNPs_all $ref_genome

echo ""
echo $tree
echo "Number of SNPs involved in HRE events:"
awk '$1!="" {print $1}' hreSNPs | sort -u | wc -l
echo "Number of HRE events:"
grep -v HRE_events hre_from_to_c | awk ' total=total+$5 {} END {print total}'
echo "Number of HRE events from outside tree:"
grep -v HRE_events hre_from_to_c | grep outside | awk ' total=total+$5 {} END {print total}'


cd ..
end

endif

exit


# Set up standing db of genbank files so you don't have to go online to annotate SNPs
mkdir GenbankFiles
cd GenbankFiles
foreach domain ( Viruses Bacteria )
mkdir $domain
cd $domain
foreach type (gbk)
mkdir Temp
cd Temp
wget "ftp://ftp.ncbi.nih.gov/genomes/$domain/all.$type.tar.gz"
tar -xvzf all.$type.tar.gz
rm *.tar.gz
mv */*  ..
rm -r *
cd ..
rm -r Temp
end
cd ..
end

# get gbk files for plasmids
foreach domain ( Plasmids)
mkdir $domain
cd $domain
foreach type (gbk)
wget "ftp://ftp.ncbi.nih.gov/genomes/$domain/plasmids.all.$type.tar.gz"
tar -xvzf plasmids.all.$type.tar.gz
mv am/ftp-genomes/Plasmids/$type/* .
rm -r am
rm *.tar.gz
end
cd ..
end
